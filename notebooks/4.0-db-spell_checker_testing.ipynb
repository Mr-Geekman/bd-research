{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование Spell Checker\n",
    "\n",
    "В этом ноутбуке будет произведено базовое тестировние написанной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T10:44:41.360708Z",
     "start_time": "2021-02-01T10:44:41.325864Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T10:44:43.862763Z",
     "start_time": "2021-02-01T10:44:41.489088Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from string import punctuation\n",
    "sys.path.append('..')\n",
    "\n",
    "import dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertForMaskedLM, BertTokenizer, BertConfig\n",
    "\n",
    "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
    "\n",
    "import kenlm\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "\n",
    "from src.models.SpellChecker import *\n",
    "from src.models.BertScorer.bert_scorer_correction import (\n",
    "    BertScorerCorrection\n",
    ")\n",
    "\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T10:44:43.923055Z",
     "start_time": "2021-02-01T10:44:43.866799Z"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_PATH = os.path.join(os.path.abspath(''), os.pardir)\n",
    "DATA_PATH = os.path.join(PROJECT_PATH, 'data')\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с того, что инициализируем все необходимые компоненты модели. Параллельно так же будет описана роль каждого компонента в системе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T19:49:57.964235Z",
     "start_time": "2021-01-29T19:49:57.922050Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_tokenizer = MosesTokenizer(lang='ru')\n",
    "raw_detokenizer = MosesDetokenizer(lang='ru')\n",
    "tokenizer = lambda x: raw_tokenizer.tokenize(x, escape=False)\n",
    "detokenizer = lambda x: raw_detokenizer.detokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T19:52:52.230413Z",
     "start_time": "2021-01-29T19:49:57.967756Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_path = os.path.join(DATA_PATH, 'external', 'russian_words', \n",
    "                          'russian_words_vocab.dict')\n",
    "vocab = SimpleVocabulary(load_path=vocab_path, save_path=vocab_path)\n",
    "handcode_table_path = os.path.join(DATA_PATH, 'processed', 'handcode_table', \n",
    "                                   'table.json')\n",
    "with open(handcode_table_path, 'r') as inf:\n",
    "    handcode_table = json.load(inf)\n",
    "candidate_generator = CandidateGenerator(\n",
    "    words=vocab.keys(), handcode_table=handcode_table, max_distance=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T19:53:07.109381Z",
     "start_time": "2021-01-29T19:52:52.233100Z"
    }
   },
   "outputs": [],
   "source": [
    "model_left_right = kenlm.LanguageModel(\n",
    "    os.path.join(MODEL_PATH, 'kenlm', 'left_right_3_100.arpa.binary')\n",
    ")\n",
    "model_right_left = kenlm.LanguageModel(\n",
    "    os.path.join(MODEL_PATH, 'kenlm', 'right_left_3_100.arpa.binary')\n",
    ")\n",
    "position_selector = KenlmPositionSelector(model_left_right, model_right_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T19:53:22.937972Z",
     "start_time": "2021-01-29T19:53:07.158184Z"
    }
   },
   "outputs": [],
   "source": [
    "BERT_PATH = os.path.join(MODEL_PATH, 'conversational_rubert')\n",
    "config = BertConfig.from_json_file(\n",
    "    os.path.join(BERT_PATH, 'bert_config.json')\n",
    ")\n",
    "model = BertForMaskedLM.from_pretrained(\n",
    "    os.path.join(BERT_PATH, 'pytorch_model.bin'),\n",
    "    config=config\n",
    ")\n",
    "bert_tokenizer = BertTokenizer(os.path.join(BERT_PATH, 'vocab.txt'))\n",
    "bert_scorer_correction = BertScorerCorrection(model, bert_tokenizer)\n",
    "agg_subtoken_func = np.mean\n",
    "bert_scorer = BertScorer(\n",
    "    bert_scorer_correction, agg_subtoken_func\n",
    ")\n",
    "candidate_scorer = CandidateScorer(bert_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T19:53:23.018723Z",
     "start_time": "2021-01-29T19:53:22.940430Z"
    }
   },
   "outputs": [],
   "source": [
    "stopping_criteria = MarginStoppingCriteria(np.log(2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T19:53:23.060696Z",
     "start_time": "2021-01-29T19:53:23.024960Z"
    }
   },
   "outputs": [],
   "source": [
    "# количество кандидатов, отбираемых position selector\n",
    "num_selected_candidates = 5\n",
    "# максимальное количество итераций\n",
    "max_it = 5\n",
    "\n",
    "spellchecker = IterativeSpellChecker(\n",
    "    candidate_generator,\n",
    "    position_selector,\n",
    "    candidate_scorer,\n",
    "    stopping_criteria,\n",
    "    tokenizer,\n",
    "    detokenizer,\n",
    "    num_selected_candidates=num_selected_candidates,\n",
    "    max_it=max_it\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучающая выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T19:53:23.119268Z",
     "start_time": "2021-01-29T19:53:23.063998Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(DATA_PATH, 'external', 'spell_ru_eval', 'train_source.txt'), \n",
    "    'r'\n",
    ") as inf:\n",
    "    sentences = inf.readlines()\n",
    "    \n",
    "with open(\n",
    "    os.path.join(DATA_PATH, 'external', 'spell_ru_eval', \n",
    "                 'train_corrected.txt'), \n",
    "    'r'\n",
    ") as inf:\n",
    "    true_sentences = inf.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим наш spell checker, подавая ему предложения батчами размера `batch_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T21:02:06.528123Z",
     "start_time": "2021-01-29T19:53:23.121583Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "sentences_corrected = []\n",
    "num_batches = int(np.ceil(len(sentences) // batch_size))\n",
    "\n",
    "for i in tqdm(range(num_batches)):\n",
    "    cur_sentences = sentences[i*batch_size:(i+1)*batch_size]\n",
    "    sentences_corrected += spellchecker(cur_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем результаты файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T21:02:07.154324Z",
     "start_time": "2021-01-29T21:02:06.533616Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p ../data/processed/results_base/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T21:02:09.152597Z",
     "start_time": "2021-01-29T21:02:09.070240Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'processed', 'results_base', 'train.txt'), 'w') as ouf:\n",
    "    ouf.writelines([sentence + '\\n' for sentence in sentences_corrected])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним скрит для измерения качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T10:45:14.107099Z",
     "start_time": "2021-02-01T10:44:46.998761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision=62.22, Interval=(59.98, 64.45)\r\n",
      "Recall=65.32, Interval=(62.97, 67.66)\r\n",
      "FMeasure=63.73, Interval=(61.44, 66.02)\r\n",
      "1128 1813 1727\r\n"
     ]
    }
   ],
   "source": [
    "!python ../src/evaluation/spell_ru_eval/evaluate.py -d ../data/processed/results_base/diffs_train.txt ../data/external/spell_ru_eval/train_source.txt ../data/external/spell_ru_eval/train_corrected.txt ../data/processed/results_base/train.txt | tail -n 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, имеем\n",
    "* True Positive: $1128$\n",
    "* Внесенных исправлений: $1813$ \n",
    "* Требуемых исправления: $1727$ \n",
    "* Precision: $62.22$, доверительный интервал: $(59.98, 64.45)$\n",
    "* Recall: $65.32$, доверительный интервал: $(62.97, 67.66)$\n",
    "* FMeasure: $63.73$, доверительный интервал: $(61.44, 66.02)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестовая выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T21:02:37.499319Z",
     "start_time": "2021-01-29T21:02:37.312393Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(DATA_PATH, 'external', 'spell_ru_eval', 'test_source.txt'), \n",
    "    'r'\n",
    ") as inf:\n",
    "    sentences = inf.readlines()\n",
    "    \n",
    "with open(\n",
    "    os.path.join(DATA_PATH, 'external', 'spell_ru_eval', \n",
    "                 'test_corrected.txt'), \n",
    "    'r'\n",
    ") as inf:\n",
    "    true_sentences = inf.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим наш spell checker, подавая ему предложения батчами размера `batch_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T22:24:56.742799Z",
     "start_time": "2021-01-29T21:02:41.367078Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "sentences_corrected = []\n",
    "num_batches = int(np.ceil(len(sentences) // batch_size))\n",
    "\n",
    "for i in tqdm(range(num_batches)):\n",
    "    cur_sentences = sentences[i*batch_size:(i+1)*batch_size]\n",
    "    sentences_corrected += spellchecker(cur_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем результаты файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T22:30:12.437618Z",
     "start_time": "2021-01-29T22:30:12.259309Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'processed', 'results_base', 'test.txt'), 'w') as ouf:\n",
    "    ouf.writelines([sentence + '\\n' for sentence in sentences_corrected])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним скрит для измерения качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T10:45:49.869843Z",
     "start_time": "2021-02-01T10:45:14.116071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision=52.86, Interval=(50.80, 54.93)\r\n",
      "Recall=59.94, Interval=(57.60, 62.28)\r\n",
      "FMeasure=56.18, Interval=(53.98, 58.38)\r\n",
      "1182 2236 1972\r\n"
     ]
    }
   ],
   "source": [
    "!python ../src/evaluation/spell_ru_eval/evaluate.py -d ../data/processed/results_base/diffs_test.txt ../data/external/spell_ru_eval/test_source.txt ../data/external/spell_ru_eval/test_corrected.txt ../data/processed/results_base/test.txt | tail -n 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, имеем\n",
    "* True Positive: $1182$\n",
    "* Внесенных исправлений: $2194$ \n",
    "* Требуемых исправления: $1972$ \n",
    "* Precision: $52.86$, доверительный интервал: $(50.80, 54.93)$\n",
    "* Recall: $59.94$, доверительный интервал: $(57.60, 62.28)$\n",
    "* FMeasure: $56.18$, доверительный интервал: $(53.98, 58.38)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что на тесте качество достаточно ощутимо падает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "1. Пока результат выглядит не очень хорошо, особенно смущает precision. Казалось, что BERT сможет более качественно выполнять исправления. Возможно, эта проблема решится если использовать какую-то модель ошибок и скоры из position selector для окончательного выбора кандидата.\n",
    "2. Пробовал заменить модель в position selector на 3-граммную модель, которая обучалась без текстов из соц. сетей &mdash; результат примерно такой же.\n",
    "3. Пробовал заменить модель в position selector на 4-граммную модель &mdash; результат примерно такой же.\n",
    "4. Пробовал увеличить максимальное расстояние Дамера-Левенштейна до двух &mdash; результат стал сильно хуже.\n",
    "5. Пробовал изменить аггрегирующую функцию по WordPiece-токенам в candidate scorer &mdash; результат стал немного хуже."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

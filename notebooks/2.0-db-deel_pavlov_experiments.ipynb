{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepPavlov experiments\n",
    "\n",
    "В этом ноутбуке я разбираюсь в том, как работать с библиотекой DeepPavlov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:10:38.047912Z",
     "start_time": "2020-11-29T16:10:38.004908Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:10:51.930953Z",
     "start_time": "2020-11-29T16:10:51.872351Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from deeppavlov import build_model, configs\n",
    "from transformers import BertForMaskedLM, BertTokenizer, BertConfig\n",
    "\n",
    "from src.models.BertScorer.bert_scorer_sentence import BertScorerSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим константы и переменные окружения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:11:23.966385Z",
     "start_time": "2020-11-29T16:11:23.916821Z"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_PATH = os.path.join(os.path.abspath(''), os.pardir)\n",
    "CONFIGS_PATH = os.path.join(PROJECT_PATH, 'src', 'configs')\n",
    "os.environ['DP_PROJECT_PATH'] = PROJECT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузим Kenlm Pruner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с того, что протестируем, как работает написанный прунер для гипотез. По итогу он должен оставить 100 гипотез, среди которых в будущем должна быть выбрана наилучшая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:11:24.866769Z",
     "start_time": "2020-11-29T16:11:24.774881Z"
    }
   },
   "outputs": [],
   "source": [
    "CONFIG_PATH = os.path.join(CONFIGS_PATH, 'levenstein_kenlm_selector.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:14:10.461442Z",
     "start_time": "2020-11-29T16:11:24.974003Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "2020-11-29 19:11:25.798 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/mrgeekman/Documents/MIPT/НИР/Repo/data/external/russian_words/russian_words_vocab.dict]\n"
     ]
    }
   ],
   "source": [
    "model = build_model(CONFIG_PATH, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:14:12.024861Z",
     "start_time": "2020-11-29T16:14:10.475197Z"
    }
   },
   "outputs": [],
   "source": [
    "lines = ['Опофеозом дня для меня сегодня стала фраза услышанная в новостях.']\n",
    "results = model(lines)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:14:12.094348Z",
     "start_time": "2020-11-29T16:14:12.027724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-52.1003520488739,\n",
       "  ['апофеозом',\n",
       "   'дня',\n",
       "   'для',\n",
       "   'меня',\n",
       "   'сегодня',\n",
       "   'стала',\n",
       "   'фраза',\n",
       "   'услышанная',\n",
       "   'в',\n",
       "   'новостях',\n",
       "   '.',\n",
       "   '</s>']),\n",
       " (-53.79301333427429,\n",
       "  ['опофеозом',\n",
       "   'дня',\n",
       "   'для',\n",
       "   'меня',\n",
       "   'сегодня',\n",
       "   'стала',\n",
       "   'фраза',\n",
       "   'услышанная',\n",
       "   'в',\n",
       "   'новостях',\n",
       "   '.',\n",
       "   '</s>']),\n",
       " (-55.94359278678894,\n",
       "  ['апофеозом',\n",
       "   'для',\n",
       "   'для',\n",
       "   'меня',\n",
       "   'сегодня',\n",
       "   'стала',\n",
       "   'фраза',\n",
       "   'услышанная',\n",
       "   'в',\n",
       "   'новостях',\n",
       "   '.',\n",
       "   '</s>']),\n",
       " (-56.38600826263428,\n",
       "  ['апофеозом',\n",
       "   'дни',\n",
       "   'для',\n",
       "   'меня',\n",
       "   'сегодня',\n",
       "   'стала',\n",
       "   'фраза',\n",
       "   'услышанная',\n",
       "   'в',\n",
       "   'новостях',\n",
       "   '.',\n",
       "   '</s>']),\n",
       " (-57.25041913986206,\n",
       "  ['апофеозом',\n",
       "   'дно',\n",
       "   'для',\n",
       "   'меня',\n",
       "   'сегодня',\n",
       "   'стала',\n",
       "   'фраза',\n",
       "   'услышанная',\n",
       "   'в',\n",
       "   'новостях',\n",
       "   '.',\n",
       "   '</s>'])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, корректное исправление есть в списке гипотез."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение BertScorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем применить к полученным кандидатам BertScorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:14:12.134891Z",
     "start_time": "2020-11-29T16:14:12.097054Z"
    }
   },
   "outputs": [],
   "source": [
    "BERT_PATH = os.path.join(PROJECT_PATH, 'models', 'rubert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:14:38.668438Z",
     "start_time": "2020-11-29T16:14:20.957204Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/mrgeekman/Documents/MIPT/НИР/Repo/notebooks/../models/rubert/pytorch_model.bin were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at /home/mrgeekman/Documents/MIPT/НИР/Repo/notebooks/../models/rubert/pytorch_model.bin and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig.from_json_file(\n",
    "    os.path.join(BERT_PATH, 'bert_config.json')\n",
    ")\n",
    "model = BertForMaskedLM.from_pretrained(\n",
    "    os.path.join(BERT_PATH, 'pytorch_model.bin'),\n",
    "    config=config\n",
    ")\n",
    "tokenizer = BertTokenizer(os.path.join(BERT_PATH, 'vocab.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:14:38.734857Z",
     "start_time": "2020-11-29T16:14:38.670795Z"
    }
   },
   "outputs": [],
   "source": [
    "scorer = BertScorerSentence(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:15:53.659536Z",
     "start_time": "2020-11-29T16:15:53.578959Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences_for_bert = [(' '.join(x[1][:-1])) for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:19:06.513940Z",
     "start_time": "2020-11-29T16:15:55.561913Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "bert_results = scorer(sentences_for_bert, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:19:20.419781Z",
     "start_time": "2020-11-29T16:19:20.364417Z"
    }
   },
   "outputs": [],
   "source": [
    "sort_indices = np.argsort(-np.array(bert_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:20:33.290836Z",
     "start_time": "2020-11-29T16:20:33.221417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "апофеозом дня для меня сегодня стала фраза услышанная в новостях . : -3.660\n",
      "апофеозом дня для меня сего дня стала фраза услышанная в новостях . : -3.695\n",
      "апофеозом дня для мене сегодня стала фраза услышанная в новостях . : -3.742\n",
      "апофеозом пня для меня сегодня стала фраза услышанная в новостях . : -3.841\n",
      "апофеозом дыня для меня сегодня стала фраза услышанная в новостях . : -3.850\n"
     ]
    }
   ],
   "source": [
    "for idx in sort_indices[:5]:\n",
    "    print(f'{sentences_for_bert[idx]} : {bert_results[idx]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим вполне вменяемый результат."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bs_research] *",
   "language": "python",
   "name": "conda-env-bs_research-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

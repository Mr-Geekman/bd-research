{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение моделей скорера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом нотбуке будет произведен сбор обучающей выборки и обучение скорера на основе ranking SVM, CatBoost использованием дополнительных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:36:58.327824Z",
     "start_time": "2021-02-04T21:36:58.293943Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:01.403353Z",
     "start_time": "2021-02-04T21:36:58.427120Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "from copy import copy, deepcopy\n",
    "from string import punctuation\n",
    "sys.path.append('..')\n",
    "\n",
    "import dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertForMaskedLM, BertTokenizer, BertConfig\n",
    "\n",
    "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
    "\n",
    "import kenlm\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "\n",
    "from src.models.SpellChecker import *\n",
    "from src.models.BertScorer.bert_scorer_correction import (\n",
    "    BertScorerCorrection\n",
    ")\n",
    "from src.evaluation.spell_ru_eval import align_sents\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import catboost\n",
    "from catboost import CatBoost, Pool, MetricVisualizer\n",
    "\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:01.438772Z",
     "start_time": "2021-02-04T21:37:01.406346Z"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_PATH = os.path.join(os.path.abspath(''), os.pardir)\n",
    "DATA_PATH = os.path.join(PROJECT_PATH, 'data')\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нахождение корректных токенов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с того, что найдем какие токены в каждой позиции правильные. Так как наша модель не умеет никак объединять токены надо будет найти те предложения, где токены исходного предложения не объединяются."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим токенизаторы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:01.482511Z",
     "start_time": "2021-02-04T21:37:01.443824Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_tokenizer = MosesTokenizer(lang='ru')\n",
    "raw_detokenizer = MosesDetokenizer(lang='ru')\n",
    "tokenizer = lambda x: raw_tokenizer.tokenize(x, escape=False)\n",
    "detokenizer = lambda x: raw_detokenizer.detokenize(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем все предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:01.551032Z",
     "start_time": "2021-02-04T21:37:01.485794Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(DATA_PATH, 'external', 'spell_ru_eval', 'train_source.txt'), \n",
    "    'r'\n",
    ") as inf:\n",
    "    sentences = inf.readlines()\n",
    "    \n",
    "with open(\n",
    "    os.path.join(DATA_PATH, 'external', 'spell_ru_eval', \n",
    "                 'train_corrected.txt'), \n",
    "    'r'\n",
    ") as inf:\n",
    "    sentences_corrected = inf.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем какое-либо случайное предложение на данный момент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:01.599820Z",
     "start_time": "2021-02-04T21:37:01.555344Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "idx = np.random.randint(0, len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:01.636371Z",
     "start_time": "2021-02-04T21:37:01.603088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Намазывем уже остывший корж \" кремом \" ( \" фромаж блан \" или творог, риккота, протертые сквозь мелкое сито, даже густая сметана подойдет ), совсем немного, только, чтобы ягоды потом прилипли.\n",
      "\n",
      "Намазываем уже остывший корж кремом фромаж блан или творог риккота протертые сквозь мелкое сито даже густая сметана подойдет совсем немного только чтобы ягоды потом прилипли\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = sentences[idx]\n",
    "sentence_corrected = sentences_corrected[idx]\n",
    "print(sentence)\n",
    "print(sentence_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:01.758569Z",
     "start_time": "2021-02-04T21:37:01.639722Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_sentence_raw = tokenizer(\n",
    "    sentence.lower().replace('ё', 'е')\n",
    ")\n",
    "tokenized_sentence_corrected = tokenizer(\n",
    "    sentence_corrected.lower().replace('ё', 'е')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберем пунктуацию из изначального предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:01.798802Z",
     "start_time": "2021-02-04T21:37:01.763040Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_sentence = []\n",
    "indices_mapping = []\n",
    "for i, token in enumerate(tokenized_sentence_raw):\n",
    "    if not re.fullmatch(f'[{punctuation}]+', token):\n",
    "        tokenized_sentence.append(token)\n",
    "        indices_mapping.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробуем убрать пунктуацию и вывести выравнивание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:01.854078Z",
     "start_time": "2021-02-04T21:37:01.801189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['намазывем']\t['намазываем']\n",
      "['уже']\t['уже']\n",
      "['остывший']\t['остывший']\n",
      "['корж']\t['корж']\n",
      "['кремом']\t['кремом']\n",
      "['фромаж']\t['фромаж']\n",
      "['блан']\t['блан']\n",
      "['или']\t['или']\n",
      "['творог']\t['творог']\n",
      "['риккота']\t['риккота']\n",
      "['протертые']\t['протертые']\n",
      "['сквозь']\t['сквозь']\n",
      "['мелкое']\t['мелкое']\n",
      "['сито']\t['сито']\n",
      "['даже']\t['даже']\n",
      "['густая']\t['густая']\n",
      "['сметана']\t['сметана']\n",
      "['подойдет']\t['подойдет']\n",
      "['совсем']\t['совсем']\n",
      "['немного']\t['немного']\n",
      "['только']\t['только']\n",
      "['чтобы']\t['чтобы']\n",
      "['ягоды']\t['ягоды']\n",
      "['потом']\t['потом']\n",
      "['прилипли']\t['прилипли']\n"
     ]
    }
   ],
   "source": [
    "alignment = align_sents(tokenized_sentence, tokenized_sentence_corrected)\n",
    "for pair in alignment:\n",
    "    left_indices, right_indices = pair\n",
    "    print(f'{tokenized_sentence[left_indices[0]:left_indices[1]]}\\t'\n",
    "          f'{tokenized_sentence_corrected[right_indices[0]:right_indices[1]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, тут выравнивание оказалось очень простым: 1 к 1. Таким образом, для каждой позиции слева мы нашли корректный токен справа. На пунктуацию можем внимания не обращать, потому что она не может попасть в позиции для исправлений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь такое надо сделать со всеми предложениями в датасете, но надо учесть, что иногда нам могут встречаться случаи, когда нескольким токенам слева соответствует один токен справа (например, когда в слове случайно вставлен пробел). Мы с таким работать не умеем, а потому будем игнорировать такие предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:01.900583Z",
     "start_time": "2021-02-04T21:37:01.858828Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_true_correction(sentence, sentence_corrected):\n",
    "    \"\"\"Find correction for sentence.\"\"\"\n",
    "    tokenized_sentence_raw = tokenizer(\n",
    "        sentence.lower().replace('ё', 'е')\n",
    "    )\n",
    "    tokenized_sentence_corrected = tokenizer(\n",
    "        sentence_corrected.lower().replace('ё', 'е')\n",
    "    )\n",
    "    # remove punctuation from source sentence and make mapping \n",
    "    # to initial indices\n",
    "    tokenized_sentence = []\n",
    "    indices_mapping = []\n",
    "    for i, token in enumerate(tokenized_sentence_raw):\n",
    "        if not re.fullmatch(f'[{punctuation}]+', token):\n",
    "            tokenized_sentence.append(token)\n",
    "            indices_mapping.append(i)\n",
    "    \n",
    "    alignment = align_sents(tokenized_sentence, tokenized_sentence_corrected)\n",
    "    answer = {}\n",
    "    for i, pair in enumerate(alignment):\n",
    "        left_indices, right_indices = pair\n",
    "        if left_indices[1] - left_indices[0] > 1:\n",
    "            return None\n",
    "        answer[indices_mapping[left_indices[0]]] = (\n",
    "            detokenizer(\n",
    "                 tokenized_sentence_corrected[\n",
    "                     right_indices[0]:right_indices[1]]\n",
    "            )\n",
    "        )\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполняем действие над всеми предложениями в обучающем датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:07.352373Z",
     "start_time": "2021-02-04T21:37:01.903697Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fail_indices = []\n",
    "succ_indices = []\n",
    "answers = {}\n",
    "for i, (sentence, sentence_corrected) in enumerate(\n",
    "    zip(sentences, sentences_corrected)\n",
    "):\n",
    "    answer = find_true_correction(sentence, sentence_corrected)\n",
    "    if answer is None:\n",
    "        fail_indices.append(i)\n",
    "    else:\n",
    "        succ_indices.append(i)\n",
    "        answers[i] = answer\n",
    "        \n",
    "sentences_to_check = [sentences[idx] for idx in succ_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как много предложений, которые мы не смогли обработать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:07.391890Z",
     "start_time": "2021-02-04T21:37:07.356735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество ошибок со слияниями: 70\n",
      "Доля ошибок со слияниями: 0.041\n"
     ]
    }
   ],
   "source": [
    "num_fails = len(fail_indices)\n",
    "all_fails = 1727 # знаем исходя из тестировния\n",
    "print(f'Количество ошибок со слияниями: {num_fails}')\n",
    "print(f'Доля ошибок со слияниями: {num_fails/all_fails:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это значение не слишком велико."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сбор обучающей выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь требуется собрать саму обучающую выборку. \n",
    "\n",
    "Пусть на вход подается некоторое предложение для исправления. В процессе работы модели position selector находит позиции для исправления и подает в candidate scorer список кандидатов. Наша задача &mdash; зафиксировать номер выбранной позиции и список пришедших кандидатов вместе с их признаками.\n",
    "\n",
    "Такое сохранение будет сделано при помощи callback-функции после вызова candidate scorer. Она соберет позиции, кандидатов с признаками, результаты скоринга при помощи BERT и запишет это в файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T09:51:43.438688Z",
     "start_time": "2021-02-04T09:51:43.393897Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T09:51:43.490426Z",
     "start_time": "2021-02-04T09:51:43.443553Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_callback_bert_scorer(num_batch):\n",
    "    def callback_bert_scorer(\n",
    "        tokenized_sentences, indices_processing_sentences, \n",
    "        candidates, positions, \n",
    "        scoring_results, scoring_info\n",
    "    ):\n",
    "        for num_sent, candidates_sentence in enumerate(candidates):\n",
    "            candidates_to_dump = []\n",
    "            position = positions[num_sent]\n",
    "            for i, candidate in enumerate(candidates_sentence[position]):\n",
    "                copy_candidate = copy(candidate)\n",
    "                copy_candidate.update(scoring_info[num_sent][i])\n",
    "                candidates_to_dump.append(copy_candidate)\n",
    "\n",
    "            key = (num_batch, indices_processing_sentences[num_sent])\n",
    "            if key not in data:\n",
    "                data[key] = []\n",
    "            data[key].append({\n",
    "                'position': position,\n",
    "                'candidates': candidates_to_dump\n",
    "            })\n",
    "    return callback_bert_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проинициализируем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T09:54:55.747415Z",
     "start_time": "2021-02-04T09:51:43.494469Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_path = os.path.join(DATA_PATH, 'external', 'russian_words', \n",
    "                          'russian_words_vocab.dict')\n",
    "vocab = SimpleVocabulary(load_path=vocab_path, save_path=vocab_path)\n",
    "handcode_table_path = os.path.join(DATA_PATH, 'processed', 'handcode_table', \n",
    "                                   'table.json')\n",
    "with open(handcode_table_path, 'r') as inf:\n",
    "    handcode_table = json.load(inf)\n",
    "candidate_generator = CandidateGenerator(\n",
    "    words=vocab.keys(), handcode_table=handcode_table, max_distance=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T09:55:18.049155Z",
     "start_time": "2021-02-04T09:54:55.750293Z"
    }
   },
   "outputs": [],
   "source": [
    "model_left_right = kenlm.LanguageModel(\n",
    "    os.path.join(MODEL_PATH, 'kenlm', 'left_right_3_100.arpa.binary')\n",
    ")\n",
    "model_right_left = kenlm.LanguageModel(\n",
    "    os.path.join(MODEL_PATH, 'kenlm', 'right_left_3_100.arpa.binary')\n",
    ")\n",
    "margin_border = np.log(2.5)\n",
    "position_selector = KenlmPositionSelector(\n",
    "    model_left_right, model_right_left, margin_border=margin_border\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T09:55:35.612140Z",
     "start_time": "2021-02-04T09:55:18.082934Z"
    }
   },
   "outputs": [],
   "source": [
    "BERT_PATH = os.path.join(MODEL_PATH, 'conversational_rubert')\n",
    "config = BertConfig.from_json_file(\n",
    "    os.path.join(BERT_PATH, 'bert_config.json')\n",
    ")\n",
    "model = BertForMaskedLM.from_pretrained(\n",
    "    os.path.join(BERT_PATH, 'pytorch_model.bin'),\n",
    "    config=config\n",
    ")\n",
    "bert_tokenizer = BertTokenizer(os.path.join(BERT_PATH, 'vocab.txt'))\n",
    "bert_scorer_correction = BertScorerCorrection(model, bert_tokenizer)\n",
    "agg_subtoken_func = 'mean'\n",
    "bert_scorer = BertScorer(\n",
    "    bert_scorer_correction, agg_subtoken_func\n",
    ")\n",
    "candidate_scorer = CandidateScorer(bert_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T09:55:35.697092Z",
     "start_time": "2021-02-04T09:55:35.615632Z"
    }
   },
   "outputs": [],
   "source": [
    "# максимальное количество итераций\n",
    "max_it = 5\n",
    "\n",
    "spellchecker = IterativeSpellChecker(\n",
    "    candidate_generator,\n",
    "    position_selector,\n",
    "    candidate_scorer,\n",
    "    tokenizer,\n",
    "    detokenizer,\n",
    "    max_it=max_it\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим сбор обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T10:54:27.904004Z",
     "start_time": "2021-02-04T09:55:35.702989Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "num_batches = int(np.ceil(len(sentences_to_check) // batch_size))\n",
    "\n",
    "for i in tqdm(range(num_batches)):\n",
    "    cur_sentences = sentences_to_check[i*batch_size:(i+1)*batch_size]\n",
    "    spellchecker(\n",
    "        cur_sentences,\n",
    "        callback_candidate_scorer=create_callback_bert_scorer(i)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведем текущие индексы предложений в исходные и сохраним данные на диск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T10:57:05.443077Z",
     "start_time": "2021-02-04T10:57:05.130514Z"
    }
   },
   "outputs": [],
   "source": [
    "data_adjusted = {}\n",
    "for key, value in data.items():\n",
    "    key_adjusted = succ_indices[key[0]*batch_size + key[1]]\n",
    "    data_adjusted[key_adjusted] = value\n",
    "    \n",
    "data = data_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T10:57:07.297500Z",
     "start_time": "2021-02-04T10:57:07.194962Z"
    }
   },
   "outputs": [],
   "source": [
    "data_with_answers = {}\n",
    "for key, value in data.items():\n",
    "    new_value = []\n",
    "    for item in value:\n",
    "        new_item = copy(item)\n",
    "        new_item['answer'] = answers[key][item['position']]\n",
    "        new_value.append(new_item)\n",
    "    data_with_answers[key] = new_value\n",
    "    \n",
    "data = data_with_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T10:57:07.841222Z",
     "start_time": "2021-02-04T10:57:07.410837Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p ../data/processed/candidate_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T10:57:08.394820Z",
     "start_time": "2021-02-04T10:57:07.937359Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'processed', 'candidate_scorer', 'data.bin'), 'wb') as ouf:\n",
    "    pickle.dump(data, ouf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аналитика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем небольшую аналитку по данным. Найдем:\n",
    "1. Количество предложений без исправлений.\n",
    "2. Среднее количество исправлений.\n",
    "3. Доля случаев, когда использовано максимальное число итераций.\n",
    "4. Доля случаев, когда нет корректного токена в списке кандидатов\n",
    "5. Среднее количество кандидатов.\n",
    "6. Доля случаев, когда надо оставить изначальный токен при изменении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:07.580402Z",
     "start_time": "2021-02-04T21:37:07.397964Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'processed', 'candidate_scorer', 'data.bin'), 'rb') as inf:\n",
    "    data = pickle.load(inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1). Количество предложений без исправлений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:07.621897Z",
     "start_time": "2021-02-04T21:37:07.582359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_to_check) - len(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, почти четверть предложений остались без исправлений. \n",
    "\n",
    "Исходя из статья, посвященной соревнованию, данные которого мы используем, на валидацию и тест было отведено в сумме 1600 корректных предложений. Они разделялись поровно и случайно, поэтому нет гарантий, что удастся получить ровно 800. Следует так же учесть, что часть ошибок модель не смогла заметиь, а часть не может заметить в принципе. Так что полученное значение выглядит правдоподобно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2). Среднее количество исправлений в предложениях, в которых хоть что-то было исправлено."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:07.987025Z",
     "start_time": "2021-02-04T21:37:07.940846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее количество исправлений: 2.125\n"
     ]
    }
   ],
   "source": [
    "num_corrections = []\n",
    "for key, value in data.items():\n",
    "    num_corrections.append(len(value))\n",
    "num_corrections = np.array(num_corrections)\n",
    "print(f'Среднее количество исправлений: {np.mean(num_corrections):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В среднем имеем примерно два исправления на предложение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3). Доля случаев, когда использовано максимальное число итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:08.312246Z",
     "start_time": "2021-02-04T21:37:08.282144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля случаев, когда использовано максимальное число итерераций: 0.105\n"
     ]
    }
   ],
   "source": [
    "print(f'Доля случаев, когда использовано максимальное число итерераций: '\n",
    "      f'{np.mean(num_corrections == 5):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4). Доля случаев, когда нет корректного токена в списке кандидатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:08.613787Z",
     "start_time": "2021-02-04T21:37:08.538853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля случаев, когда нет корректного токена в списке: 0.033\n"
     ]
    }
   ],
   "source": [
    "exist_correct_candidate = []\n",
    "for key, value in data.items():\n",
    "    for item in value:\n",
    "        answer = item['answer']\n",
    "        candidates = [x['token'] for x in item['candidates']]\n",
    "        exist_correct_candidate.append(answer in candidates)\n",
    "        \n",
    "print(f'Доля случаев, когда нет корректного токена в списке: '\n",
    "      f'{1-np.mean(exist_correct_candidate):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5). Среднее количество кандидатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:08.813712Z",
     "start_time": "2021-02-04T21:37:08.777286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее количество кандидатов: 19.016\n"
     ]
    }
   ],
   "source": [
    "num_candidates = []\n",
    "for key, value in data.items():\n",
    "    for item in value:\n",
    "        num_candidates.append(len(item['candidates']))\n",
    "print(f'Среднее количество кандидатов: {np.mean(num_candidates):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6). Доля случаев, когда надо оставить изначальный токен при изменении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:09.064344Z",
     "start_time": "2021-02-04T21:37:09.019792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля случаев, когда надо оставить изначальный токен: 0.424\n"
     ]
    }
   ],
   "source": [
    "remain_original = []\n",
    "for key, value in data.items():\n",
    "    for item in value:\n",
    "        answer = item['answer']\n",
    "        candidates = [x['token'] for x in item['candidates'] if x['is_original']]\n",
    "        remain_original.append(answer in candidates)\n",
    "        \n",
    "print(f'Доля случаев, когда надо оставить изначальный токен: '\n",
    "      f'{np.mean(remain_original):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, изначальный токен надо оставить в достаточно большом количестве случаев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим модель. Будем решать задачу ранжирования, потому что хотим уметь выбирать одного наилучшего кандидата.\n",
    "\n",
    "В качестве итоговой метрики возьмем accuracy: частоту правильного угадывания верного исправления."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка датафрейма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с создания датафрейма. Каждому случаю ранжирования надо присвоить отдельную группу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:10.142755Z",
     "start_time": "2021-02-04T21:37:09.777224Z"
    }
   },
   "outputs": [],
   "source": [
    "candidate_keys = list(data[0][0]['candidates'][0].keys())\n",
    "df_dict = {}\n",
    "df_dict['group'] = []\n",
    "df_dict['answer'] = []\n",
    "group_idx = 0\n",
    "df_dict.update({key: [] for key in candidate_keys})\n",
    "for key_data, values_data in data.items():\n",
    "    for i, item in enumerate(values_data):\n",
    "        for candidate in item['candidates']:\n",
    "            df_dict['group'].append(group_idx)\n",
    "            df_dict['answer'].append(item['answer'])\n",
    "            for key, value in candidate.items():\n",
    "                df_dict[key].append(value)\n",
    "        group_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:10.412836Z",
     "start_time": "2021-02-04T21:37:10.146001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>answer</th>\n",
       "      <th>token</th>\n",
       "      <th>is_title</th>\n",
       "      <th>is_upper</th>\n",
       "      <th>is_lower</th>\n",
       "      <th>is_first</th>\n",
       "      <th>contains_space</th>\n",
       "      <th>contains_hyphen</th>\n",
       "      <th>from_levenshtein_searcher</th>\n",
       "      <th>...</th>\n",
       "      <th>is_current</th>\n",
       "      <th>from_vocabulary</th>\n",
       "      <th>kenlm_left_right_score</th>\n",
       "      <th>kenlm_right_left_score</th>\n",
       "      <th>kenlm_agg_score</th>\n",
       "      <th>margin_kenlm_agg</th>\n",
       "      <th>bert_score_len</th>\n",
       "      <th>bert_score_sum</th>\n",
       "      <th>bert_score_mean</th>\n",
       "      <th>is_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>кто бы</td>\n",
       "      <td>ктобы</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-7.820433</td>\n",
       "      <td>-8.266124</td>\n",
       "      <td>-8.037104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.701331</td>\n",
       "      <td>-6.350665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>кто бы</td>\n",
       "      <td>кто ы</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-9.029816</td>\n",
       "      <td>-9.861761</td>\n",
       "      <td>-9.427470</td>\n",
       "      <td>-1.390366</td>\n",
       "      <td>2</td>\n",
       "      <td>-17.923715</td>\n",
       "      <td>-8.961858</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>кто бы</td>\n",
       "      <td>кт бы</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-9.154133</td>\n",
       "      <td>-9.646735</td>\n",
       "      <td>-9.393981</td>\n",
       "      <td>-1.356877</td>\n",
       "      <td>3</td>\n",
       "      <td>-30.302781</td>\n",
       "      <td>-10.100927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>кто бы</td>\n",
       "      <td>кто бы</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-5.504485</td>\n",
       "      <td>-4.735255</td>\n",
       "      <td>-5.090977</td>\n",
       "      <td>2.946127</td>\n",
       "      <td>2</td>\n",
       "      <td>-7.410320</td>\n",
       "      <td>-3.705160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>кто бы</td>\n",
       "      <td>к обы</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-10.980565</td>\n",
       "      <td>-12.116825</td>\n",
       "      <td>-11.520746</td>\n",
       "      <td>-3.483642</td>\n",
       "      <td>2</td>\n",
       "      <td>-30.354878</td>\n",
       "      <td>-15.177439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   group  answer   token  is_title  is_upper  is_lower  is_first  \\\n",
       "0      0  кто бы   ктобы     False     False      True     False   \n",
       "1      0  кто бы   кто ы     False     False      True     False   \n",
       "2      0  кто бы   кт бы     False     False      True     False   \n",
       "3      0  кто бы  кто бы     False     False      True     False   \n",
       "4      0  кто бы   к обы     False     False      True     False   \n",
       "\n",
       "   contains_space  contains_hyphen  from_levenshtein_searcher  ...  \\\n",
       "0           False            False                      False  ...   \n",
       "1            True            False                       True  ...   \n",
       "2            True            False                       True  ...   \n",
       "3            True            False                       True  ...   \n",
       "4            True            False                       True  ...   \n",
       "\n",
       "   is_current  from_vocabulary  kenlm_left_right_score  \\\n",
       "0        True            False               -7.820433   \n",
       "1       False             True               -9.029816   \n",
       "2       False             True               -9.154133   \n",
       "3       False             True               -5.504485   \n",
       "4       False             True              -10.980565   \n",
       "\n",
       "   kenlm_right_left_score  kenlm_agg_score  margin_kenlm_agg  bert_score_len  \\\n",
       "0               -8.266124        -8.037104          0.000000               2   \n",
       "1               -9.861761        -9.427470         -1.390366               2   \n",
       "2               -9.646735        -9.393981         -1.356877               3   \n",
       "3               -4.735255        -5.090977          2.946127               2   \n",
       "4              -12.116825       -11.520746         -3.483642               2   \n",
       "\n",
       "   bert_score_sum  bert_score_mean  is_correct  \n",
       "0      -12.701331        -6.350665           0  \n",
       "1      -17.923715        -8.961858           0  \n",
       "2      -30.302781       -10.100927           0  \n",
       "3       -7.410320        -3.705160           1  \n",
       "4      -30.354878       -15.177439           0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df_dict)\n",
    "df['is_correct'] = (df['token'] == df['answer']).astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:10.449197Z",
     "start_time": "2021-02-04T21:37:10.416500Z"
    }
   },
   "outputs": [],
   "source": [
    "groups = df['group'].reset_index(drop=True).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BertScorer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала посмотрим, какое качество можно получить, используя уже известный нам `BertScorer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:13.817977Z",
     "start_time": "2021-02-04T21:37:10.451315Z"
    }
   },
   "outputs": [],
   "source": [
    "succ_predictions = []\n",
    "for group in groups:\n",
    "    df_group = df[df.group == group]\n",
    "    scores = df_group['bert_score_mean']\n",
    "    prediction_idx = np.argmax(scores)\n",
    "    succ_predictions.append(\n",
    "        df_group.answer.iloc[prediction_idx] \n",
    "        == df_group.token.iloc[prediction_idx]\n",
    "    )\n",
    "\n",
    "succ_predictions = np.array(succ_predictions)\n",
    "accuracy = np.mean(succ_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:13.869245Z",
     "start_time": "2021-02-04T21:37:13.821796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.508\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим не очень хорошее значение. Ниже мы увидим, что его можно сильно улучшить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем pair-wise подход, а именно ranking SVM. Для каждой позиции мы знаем какой из кандидатов (если, конечно, оптимальный кандидат есть в списке) является наилучшим. В таком случае в паре кандидатов, где один правильным мы знаем какой из них лучше &mdash; так и построим обучающую выборку.\n",
    "\n",
    "Следует вспомнить, что ranking SVM будет обучаться на разницах признаковых векторов и предсказывать класс такого \"разностного\" объекта. Для применения этой модели надо будет запустить ее на всех признаковых векторах и найти самое большое значение decision function (это следствие линейности модели)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь следует создать общий dataframe для попарного подхода. Таргет равен $1$, если кандидат, из которого вычитают строго лучше вычитаемого и $0$ если ситуация обратная (случай, когда не знаем какой из кандидатов лучше не рассматриваем).\n",
    "\n",
    "Также следует заметить, что признаки: `is_title`, `is_upper`, `is_lower`, `is_first` в нашем подходе оказываются бесполезными, потому что они всегда будут нулевыми (внутри одной группы они у всех одинаковы). Тем не менее, мы их оставим для удобства инференса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:37:13.906949Z",
     "start_time": "2021-02-04T21:37:13.873681Z"
    }
   },
   "outputs": [],
   "source": [
    "svm_keys = candidate_keys + ['is_correct']\n",
    "svm_keys.remove('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:38:35.410134Z",
     "start_time": "2021-02-04T21:37:13.912615Z"
    }
   },
   "outputs": [],
   "source": [
    "df_svm = pd.DataFrame(columns=svm_keys + ['group'])\n",
    "for group in df.group.unique():\n",
    "    cur_data = df[df.group == group]\n",
    "    cur_correct = cur_data[cur_data.is_correct.astype(bool)][svm_keys]\n",
    "    cur_incorrect = cur_data[~cur_data.is_correct.astype(bool)][svm_keys]\n",
    "    if not cur_correct.empty:\n",
    "        negative_data = (cur_incorrect.astype(float) \n",
    "                         - cur_correct.iloc[0].astype(float))\n",
    "        positive_data = -negative_data\n",
    "        negative_data['group'] = group\n",
    "        positive_data['group'] = group\n",
    "        negative_data['is_correct'] = 0\n",
    "        positive_data['is_correct'] = 1\n",
    "        df_svm = df_svm.append(negative_data)\n",
    "        df_svm = df_svm.append(positive_data)\n",
    "\n",
    "df_svm = df_svm.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переименуем колонки, чтобы было понятнее, что представляет из себя этот датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:38:35.573697Z",
     "start_time": "2021-02-04T21:38:35.413570Z"
    }
   },
   "outputs": [],
   "source": [
    "df_svm['is_better'] = df_svm['is_correct'].astype(int)\n",
    "df_svm.drop(columns=['is_correct'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:38:35.633876Z",
     "start_time": "2021-02-04T21:38:35.578246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_title</th>\n",
       "      <th>is_upper</th>\n",
       "      <th>is_lower</th>\n",
       "      <th>is_first</th>\n",
       "      <th>contains_space</th>\n",
       "      <th>contains_hyphen</th>\n",
       "      <th>from_levenshtein_searcher</th>\n",
       "      <th>from_phonetic_searcher</th>\n",
       "      <th>from_handcode_searcher</th>\n",
       "      <th>is_original</th>\n",
       "      <th>...</th>\n",
       "      <th>from_vocabulary</th>\n",
       "      <th>kenlm_left_right_score</th>\n",
       "      <th>kenlm_right_left_score</th>\n",
       "      <th>kenlm_agg_score</th>\n",
       "      <th>margin_kenlm_agg</th>\n",
       "      <th>bert_score_len</th>\n",
       "      <th>bert_score_sum</th>\n",
       "      <th>bert_score_mean</th>\n",
       "      <th>group</th>\n",
       "      <th>is_better</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.315948</td>\n",
       "      <td>-3.530869</td>\n",
       "      <td>-2.946127</td>\n",
       "      <td>-2.946127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.291010</td>\n",
       "      <td>-2.645505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.525331</td>\n",
       "      <td>-5.126506</td>\n",
       "      <td>-4.336493</td>\n",
       "      <td>-4.336493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.513395</td>\n",
       "      <td>-5.256697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.649648</td>\n",
       "      <td>-4.911480</td>\n",
       "      <td>-4.303004</td>\n",
       "      <td>-4.303004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-22.892460</td>\n",
       "      <td>-6.395767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.476080</td>\n",
       "      <td>-7.381570</td>\n",
       "      <td>-6.429769</td>\n",
       "      <td>-6.429769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-22.944558</td>\n",
       "      <td>-11.472279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.111958</td>\n",
       "      <td>-10.026857</td>\n",
       "      <td>-9.075175</td>\n",
       "      <td>-9.075175</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-37.236293</td>\n",
       "      <td>-11.177044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_title  is_upper  is_lower  is_first  contains_space  contains_hyphen  \\\n",
       "0       0.0       0.0       0.0       0.0            -1.0              0.0   \n",
       "1       0.0       0.0       0.0       0.0             0.0              0.0   \n",
       "2       0.0       0.0       0.0       0.0             0.0              0.0   \n",
       "4       0.0       0.0       0.0       0.0             0.0              0.0   \n",
       "5       0.0       0.0       0.0       0.0             0.0              0.0   \n",
       "\n",
       "   from_levenshtein_searcher  from_phonetic_searcher  from_handcode_searcher  \\\n",
       "0                       -1.0                     0.0                     0.0   \n",
       "1                        0.0                     0.0                     0.0   \n",
       "2                        0.0                     0.0                     0.0   \n",
       "4                        0.0                     0.0                     0.0   \n",
       "5                        0.0                     0.0                     0.0   \n",
       "\n",
       "   is_original  ...  from_vocabulary  kenlm_left_right_score  \\\n",
       "0          1.0  ...             -1.0               -2.315948   \n",
       "1          0.0  ...              0.0               -3.525331   \n",
       "2          0.0  ...              0.0               -3.649648   \n",
       "4          0.0  ...              0.0               -5.476080   \n",
       "5          0.0  ...              0.0               -8.111958   \n",
       "\n",
       "   kenlm_right_left_score  kenlm_agg_score  margin_kenlm_agg  bert_score_len  \\\n",
       "0               -3.530869        -2.946127         -2.946127             0.0   \n",
       "1               -5.126506        -4.336493         -4.336493             0.0   \n",
       "2               -4.911480        -4.303004         -4.303004             1.0   \n",
       "4               -7.381570        -6.429769         -6.429769             0.0   \n",
       "5              -10.026857        -9.075175         -9.075175             1.0   \n",
       "\n",
       "   bert_score_sum  bert_score_mean  group  is_better  \n",
       "0       -5.291010        -2.645505    0.0          0  \n",
       "1      -10.513395        -5.256697    0.0          0  \n",
       "2      -22.892460        -6.395767    0.0          0  \n",
       "4      -22.944558       -11.472279    0.0          0  \n",
       "5      -37.236293       -11.177044    0.0          0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_svm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на размер датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:38:35.685829Z",
     "start_time": "2021-02-04T21:38:35.637063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100128, 21)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_svm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достаточно большой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем данные к виду, с которым будем работать в sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:38:35.775349Z",
     "start_time": "2021-02-04T21:38:35.688349Z"
    }
   },
   "outputs": [],
   "source": [
    "to_drop = [\n",
    "    'is_better', 'group'\n",
    "]\n",
    "X = df_svm.drop(columns=to_drop).reset_index(drop=True)\n",
    "groups_svm = df_svm['group'].reset_index(drop=True)\n",
    "y = df_svm['is_better'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:38:35.869047Z",
     "start_time": "2021-02-04T21:38:35.778433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_title</th>\n",
       "      <th>is_upper</th>\n",
       "      <th>is_lower</th>\n",
       "      <th>is_first</th>\n",
       "      <th>contains_space</th>\n",
       "      <th>contains_hyphen</th>\n",
       "      <th>from_levenshtein_searcher</th>\n",
       "      <th>from_phonetic_searcher</th>\n",
       "      <th>from_handcode_searcher</th>\n",
       "      <th>is_original</th>\n",
       "      <th>is_current</th>\n",
       "      <th>from_vocabulary</th>\n",
       "      <th>kenlm_left_right_score</th>\n",
       "      <th>kenlm_right_left_score</th>\n",
       "      <th>kenlm_agg_score</th>\n",
       "      <th>margin_kenlm_agg</th>\n",
       "      <th>bert_score_len</th>\n",
       "      <th>bert_score_sum</th>\n",
       "      <th>bert_score_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.315948</td>\n",
       "      <td>-3.530869</td>\n",
       "      <td>-2.946127</td>\n",
       "      <td>-2.946127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.291010</td>\n",
       "      <td>-2.645505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.525331</td>\n",
       "      <td>-5.126506</td>\n",
       "      <td>-4.336493</td>\n",
       "      <td>-4.336493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.513395</td>\n",
       "      <td>-5.256697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.649648</td>\n",
       "      <td>-4.911480</td>\n",
       "      <td>-4.303004</td>\n",
       "      <td>-4.303004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-22.892460</td>\n",
       "      <td>-6.395767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.476080</td>\n",
       "      <td>-7.381570</td>\n",
       "      <td>-6.429769</td>\n",
       "      <td>-6.429769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-22.944558</td>\n",
       "      <td>-11.472279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.111958</td>\n",
       "      <td>-10.026857</td>\n",
       "      <td>-9.075175</td>\n",
       "      <td>-9.075175</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-37.236293</td>\n",
       "      <td>-11.177044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_title  is_upper  is_lower  is_first  contains_space  contains_hyphen  \\\n",
       "0       0.0       0.0       0.0       0.0            -1.0              0.0   \n",
       "1       0.0       0.0       0.0       0.0             0.0              0.0   \n",
       "2       0.0       0.0       0.0       0.0             0.0              0.0   \n",
       "3       0.0       0.0       0.0       0.0             0.0              0.0   \n",
       "4       0.0       0.0       0.0       0.0             0.0              0.0   \n",
       "\n",
       "   from_levenshtein_searcher  from_phonetic_searcher  from_handcode_searcher  \\\n",
       "0                       -1.0                     0.0                     0.0   \n",
       "1                        0.0                     0.0                     0.0   \n",
       "2                        0.0                     0.0                     0.0   \n",
       "3                        0.0                     0.0                     0.0   \n",
       "4                        0.0                     0.0                     0.0   \n",
       "\n",
       "   is_original  is_current  from_vocabulary  kenlm_left_right_score  \\\n",
       "0          1.0         1.0             -1.0               -2.315948   \n",
       "1          0.0         0.0              0.0               -3.525331   \n",
       "2          0.0         0.0              0.0               -3.649648   \n",
       "3          0.0         0.0              0.0               -5.476080   \n",
       "4          0.0         0.0              0.0               -8.111958   \n",
       "\n",
       "   kenlm_right_left_score  kenlm_agg_score  margin_kenlm_agg  bert_score_len  \\\n",
       "0               -3.530869        -2.946127         -2.946127             0.0   \n",
       "1               -5.126506        -4.336493         -4.336493             0.0   \n",
       "2               -4.911480        -4.303004         -4.303004             1.0   \n",
       "3               -7.381570        -6.429769         -6.429769             0.0   \n",
       "4              -10.026857        -9.075175         -9.075175             1.0   \n",
       "\n",
       "   bert_score_sum  bert_score_mean  \n",
       "0       -5.291010        -2.645505  \n",
       "1      -10.513395        -5.256697  \n",
       "2      -22.892460        -6.395767  \n",
       "3      -22.944558       -11.472279  \n",
       "4      -37.236293       -11.177044  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели и ее тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим модель и протестируем ее. Для этого будем делать кросс-валидацию по номерам группы, а на оставшихся для тестирования группах будем проверять, что самое большое предсказание получает лучший кандидат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:38:57.305045Z",
     "start_time": "2021-02-04T21:38:35.871597Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrgeekman/Programs/anaconda3/envs/bs_research/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mrgeekman/Programs/anaconda3/envs/bs_research/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mrgeekman/Programs/anaconda3/envs/bs_research/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mrgeekman/Programs/anaconda3/envs/bs_research/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/mrgeekman/Programs/anaconda3/envs/bs_research/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold()\n",
    "accuracy_values = []\n",
    "for groups_indices_train, groups_indices_test in kf.split(groups):\n",
    "    groups_train = groups[groups_indices_train]\n",
    "    X_train = X.loc[groups_svm.isin(groups_train)]\n",
    "    y_train = y.loc[groups_svm.isin(groups_train)]\n",
    "    model = Pipeline(\n",
    "        [('scaler', StandardScaler()), ('svc', LinearSVC(random_state=42))]\n",
    "    )\n",
    "    model = LinearSVC(random_state=42, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # test accuracy of prediction\n",
    "    succ_predictions = []\n",
    "    for group in groups[groups_indices_test]:\n",
    "        df_group = df[df.group == group]\n",
    "        X_test = df_group[X_train.columns]\n",
    "        scores = model.decision_function(X_test)\n",
    "        prediction_idx = np.argmax(scores)\n",
    "        succ_predictions.append(\n",
    "            df_group.answer.iloc[prediction_idx] \n",
    "            == df_group.token.iloc[prediction_idx]\n",
    "        )\n",
    "        \n",
    "    succ_predictions = np.array(succ_predictions)\n",
    "    accuracy_values.append(np.mean(succ_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T11:46:49.461827Z",
     "start_time": "2021-01-27T11:46:49.397159Z"
    }
   },
   "source": [
    "Посмотрим на среднее значение accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:38:57.340023Z",
     "start_time": "2021-02-04T21:38:57.307731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.897\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(accuracy_values)\n",
    "print(f'Accuracy: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если убрать признаки `bert_score_len`, `bert_score_sum`, `bert_score_mean`, то получилось значение $0.887$. Видим, что результат хуже примерно на $1\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение получилось гораздо лучше, чем при использовании только `bert_score`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель на всех данных и сохраним ее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:38:58.135364Z",
     "start_time": "2021-02-04T21:38:57.343705Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrgeekman/Programs/anaconda3/envs/bs_research/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svc', LinearSVC(random_state=42))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline(\n",
    "        [('scaler', StandardScaler()), ('svc', LinearSVC(random_state=42))]\n",
    ")\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T19:07:10.742498Z",
     "start_time": "2021-02-04T19:07:10.695302Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(MODEL_PATH, 'candidate_scorer', 'svm.bin'), 'wb') as ouf:\n",
    "    pickle.dump(model, ouf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на веса коэффициентов в модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:38:58.178873Z",
     "start_time": "2021-02-04T21:38:58.138522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_title: 0.000\n",
      "is_upper: 0.000\n",
      "is_lower: 0.000\n",
      "is_first: 0.000\n",
      "contains_space: 0.409\n",
      "contains_hyphen: 0.164\n",
      "from_levenshtein_searcher: 1.046\n",
      "from_phonetic_searcher: 0.674\n",
      "from_handcode_searcher: 0.695\n",
      "is_original: 2.424\n",
      "is_current: -0.136\n",
      "from_vocabulary: 0.054\n",
      "kenlm_left_right_score: 1.007\n",
      "kenlm_right_left_score: 1.226\n",
      "kenlm_agg_score: -0.072\n",
      "margin_kenlm_agg: -0.072\n",
      "bert_score_len: 0.022\n",
      "bert_score_sum: 0.022\n",
      "bert_score_mean: 0.834\n"
     ]
    }
   ],
   "source": [
    "for coef, feature_name in zip(model['svc'].coef_.ravel(), X.columns.tolist()):\n",
    "    print(f'{feature_name}: {coef:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Как ожидалось, модель проигнорировала первые четыре признака.\n",
    "2. Модель дает высокую оценку коэффициенту перед индикатором изначального токена. То есть модель дает большое предпочтение изначальному токену.\n",
    "3. Модель выше оценивает, что исправление пришло из levenshtein searcher, хотя казалось, что самый большой вклад должен иметь кандидат из handcode searcher, ведь он почти всегда дает правильное исправление.\n",
    "4. Модель сильнее реагирует на наличие пробелов, чем на наличие дефисов.\n",
    "5. Среди всех скоров от BERT наибольшее влияние оказывает скор после аггрегации средним. Тем не менее, даже так этот коэффициент по модулю меньше коэффициентов, соответствующих kenlm.\n",
    "6. Модель практически проигнорировала признаки из kenlm помимо скоров от левой и правой моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем обучить модель CatBoost. Такая модель уже сможет утилизировать первые те признаки, которые проигнорировала предыдущая. Логичным кажется оптимизировать метрику MRR, так как внутри каждой группы имеем всего один релевантный объект."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Надо создать `Pool` для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:38:58.494114Z",
     "start_time": "2021-02-04T21:38:58.185640Z"
    }
   },
   "outputs": [],
   "source": [
    "to_drop = [\n",
    "    'group', 'is_correct', 'answer', 'token'\n",
    "]\n",
    "pool_catboost = Pool(\n",
    "    data=df.drop(columns=to_drop),\n",
    "    label=df['is_correct'],\n",
    "    group_id=df['group']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели и ее тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим модель и протестируем ее при помощи кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:38:58.544587Z",
     "start_time": "2021-02-04T21:38:58.496958Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_catboost_model(params):\n",
    "    kf = KFold()\n",
    "    accuracy_values = []\n",
    "    tree_counts = []\n",
    "    for groups_indices_train, groups_indices_test in kf.split(groups):\n",
    "        groups_train = groups[groups_indices_train]\n",
    "        df_train = df[df['group'].isin(groups_train)]\n",
    "        pool_train = Pool(\n",
    "            data=df_train.drop(\n",
    "                columns=to_drop\n",
    "            ),\n",
    "            label=df_train['is_correct'],\n",
    "            group_id=df_train['group']\n",
    "        )\n",
    "\n",
    "        groups_test = groups[groups_indices_test]\n",
    "        df_test = df[df['group'].isin(groups_test)]\n",
    "        pool_test = Pool(\n",
    "            data=df_test.drop(\n",
    "                columns=to_drop\n",
    "            ),\n",
    "            label=df_test['is_correct'],\n",
    "            group_id=df_test['group']\n",
    "        )\n",
    "\n",
    "        model = CatBoost(params)\n",
    "        model.fit(pool_train, eval_set=pool_test)\n",
    "        tree_counts.append(model.tree_count_)\n",
    "        accuracy_values.append(\n",
    "            model.evals_result_[\n",
    "                'validation'\n",
    "            ]['PrecisionAt:top=1'][model.tree_count_-1]\n",
    "        )\n",
    "    return np.mean(accuracy_values), np.mean(tree_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:34:12.122265Z",
     "start_time": "2021-02-04T21:34:12.060490Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function': 'PairLogit',\n",
    "    'eval_metric': 'PrecisionAt:top=1',\n",
    "    'random_seed': 42,\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "test_catboost_model(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T11:46:49.461827Z",
     "start_time": "2021-01-27T11:46:49.397159Z"
    }
   },
   "source": [
    "Посмотрим на среднее значение accuracy для разных функций потерь:\n",
    "\n",
    "* RMSE: $0.897$\n",
    "* QueryRMSE: $0.902$\n",
    "* PairLogit: $0.916$ \n",
    "* YetiRank: $0.914$\n",
    "* YetiRankPairwise: $0.897$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получившиеся значения лучше значений, полученных в SVM. Как видим, лучше всего взять в качестве лосса PairLogit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же самое, но если убрать признаки `bert_score_len`, `bert_score_sum`, `bert_score_mean`:\n",
    "\n",
    "* RMSE: $0.891$\n",
    "* QueryRMSE: $0.898$\n",
    "* PairLogit: $0.906$ \n",
    "* YetiRank: $0.901$\n",
    "* YetiRankPairwise: $0.883$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, без признаков BERT опять падение примерно на $1\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель на всех данных и сохраним ее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:40:37.443766Z",
     "start_time": "2021-02-04T21:38:58.549021Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function': 'PairLogit',\n",
    "    'random_seed': 42,\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "model = CatBoost(params)\n",
    "model.fit(pool_catboost)\n",
    "model.shrink(350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:36:38.913915Z",
     "start_time": "2021-02-04T21:36:38.875162Z"
    }
   },
   "outputs": [],
   "source": [
    "save_path = os.path.join(MODEL_PATH, 'candidate_scorer', 'catboost_no_bert.cbm')\n",
    "model.save_model(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на значимости различных признаков в модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:40:38.530412Z",
     "start_time": "2021-02-04T21:40:37.446490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_title: 0.036\n",
      "is_upper: 0.025\n",
      "is_lower: 0.077\n",
      "is_first: 0.324\n",
      "contains_space: 0.478\n",
      "contains_hyphen: 0.232\n",
      "from_levenshtein_searcher: 1.834\n",
      "from_phonetic_searcher: 2.475\n",
      "from_handcode_searcher: 0.062\n",
      "is_original: 65.921\n",
      "is_current: 0.050\n",
      "from_vocabulary: 0.152\n",
      "kenlm_left_right_score: 1.053\n",
      "kenlm_right_left_score: 0.652\n",
      "kenlm_agg_score: 1.604\n",
      "margin_kenlm_agg: 11.174\n",
      "bert_score_len: 0.454\n",
      "bert_score_sum: 0.558\n",
      "bert_score_mean: 4.472\n"
     ]
    }
   ],
   "source": [
    "feature_importances = model.get_feature_importance(pool_catboost)\n",
    "feature_names = model.feature_names_\n",
    "for feature_name, importance in zip(feature_names, feature_importances):\n",
    "    print(f'{feature_name}: {importance*1000:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Модель практически проигнорировала первые 3 признака.\n",
    "2. Модель обращает внимание на то, является ли токен первым в предложении.\n",
    "3. Модель дает высокую оценку коэффициенту перед индикатором изначального токена. То есть модель дает большое предпочтение изначальному токену. В то же время модель почти не обращает внимание на то текущий это токен или нет.\n",
    "4. Модель выше оценивает, что исправление пришло из phonetic searcher, затем levenshtein searcher и самое наименьшее влияние имеет handcode searcher.\n",
    "5. Модель оценивает влияние дефисов и пробелов примерно в одинаковом порядке.\n",
    "6. Среди скоров kenlm наибольшее внимание уделено скору, который отвечает за превосходство рассматриваемого кандидата над используемым на данный момент.\n",
    "7. Среди скоров BERT наибольшее внимание уделено аггрегации при помощи среднего."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "1. В этом ноутбуке была собрана обучающая выборка для candidate scorer, который использует другие признаки помимо скоров из BERT.\n",
    "2. Было показано, что модель, основанная только на `bert_score` сильно уступает моделям, которые утилизируют также другие признаки.\n",
    "3. Была обучена модель ranking SVM с точностью около $90.0\\%$.\n",
    "4. Была обучена модель CatBoost с точностью около $91.5\\%$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование Spell Checker с использованием дополнительных признаков\n",
    "\n",
    "В этом ноутбуке будет произведено тестирование модели, в которой в candidate scorer используются модели на основе множества признаков помимо BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:46:18.510014Z",
     "start_time": "2021-02-17T09:46:18.379836Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:46:22.709219Z",
     "start_time": "2021-02-17T09:46:18.587009Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "from string import punctuation\n",
    "sys.path.append('..')\n",
    "\n",
    "import dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertForMaskedLM, BertTokenizer, BertConfig\n",
    "\n",
    "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
    "\n",
    "import kenlm\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "\n",
    "from src.models.SpellChecker import *\n",
    "from src.models.BertScorer.bert_scorer_correction import (\n",
    "    BertScorerCorrection\n",
    ")\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:46:22.790691Z",
     "start_time": "2021-02-17T09:46:22.714015Z"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_PATH = os.path.join(os.path.abspath(''), os.pardir)\n",
    "DATA_PATH = os.path.join(PROJECT_PATH, 'data')\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с того, что инициализируем все необходимые компоненты модели. Параллельно так же будет описана роль каждого компонента в системе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:46:22.876117Z",
     "start_time": "2021-02-17T09:46:22.797590Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_tokenizer = MosesTokenizer(lang='ru')\n",
    "raw_detokenizer = MosesDetokenizer(lang='ru')\n",
    "tokenizer = lambda x: raw_tokenizer.tokenize(x, escape=False)\n",
    "detokenizer = lambda x: raw_detokenizer.detokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:49:53.655635Z",
     "start_time": "2021-02-17T09:46:22.879919Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_path = os.path.join(DATA_PATH, 'external', 'russian_words', \n",
    "                          'russian_words_vocab.dict')\n",
    "vocab = SimpleVocabulary(load_path=vocab_path, save_path=vocab_path)\n",
    "handcode_table_path = os.path.join(DATA_PATH, 'processed', 'handcode_table', \n",
    "                                   'table.json')\n",
    "with open(handcode_table_path, 'r') as inf:\n",
    "    handcode_table = json.load(inf)\n",
    "candidate_generator = CandidateGenerator(\n",
    "    words=vocab.keys(), handcode_table=handcode_table, max_distance=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:50:17.969644Z",
     "start_time": "2021-02-17T09:49:53.663859Z"
    }
   },
   "outputs": [],
   "source": [
    "model_left_right = kenlm.LanguageModel(\n",
    "    os.path.join(MODEL_PATH, 'kenlm', 'left_right_3_100.arpa.binary')\n",
    ")\n",
    "model_right_left = kenlm.LanguageModel(\n",
    "    os.path.join(MODEL_PATH, 'kenlm', 'right_left_3_100.arpa.binary')\n",
    ")\n",
    "margin_border = np.log(2.5)\n",
    "position_selector = KenlmMarginPositionSelector(\n",
    "    model_left_right, model_right_left, margin_border=margin_border\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:50:37.083154Z",
     "start_time": "2021-02-17T09:50:17.990318Z"
    }
   },
   "outputs": [],
   "source": [
    "BERT_PATH = os.path.join(MODEL_PATH, 'conversational_rubert')\n",
    "config = BertConfig.from_json_file(\n",
    "    os.path.join(BERT_PATH, 'bert_config.json')\n",
    ")\n",
    "model = BertForMaskedLM.from_pretrained(\n",
    "    os.path.join(BERT_PATH, 'pytorch_model.bin'),\n",
    "    config=config\n",
    ")\n",
    "bert_tokenizer = BertTokenizer(os.path.join(BERT_PATH, 'vocab.txt'))\n",
    "bert_scorer_correction = BertScorerCorrection(model, bert_tokenizer)\n",
    "agg_subtoken_func = 'mean'\n",
    "bert_scorer = BertScorer(\n",
    "    bert_scorer_correction, agg_subtoken_func\n",
    ")\n",
    "\n",
    "with open(os.path.join(MODEL_PATH, 'candidate_scorer', 'svm.bin'), 'rb') as inf:\n",
    "    svm_model = pickle.load(inf)\n",
    "\n",
    "svm_scorer = SVMScorer(svm_model, bert_scorer=bert_scorer)\n",
    "candidate_scorer = CandidateScorer(svm_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:50:37.143358Z",
     "start_time": "2021-02-17T09:50:37.089012Z"
    }
   },
   "outputs": [],
   "source": [
    "# максимальное количество итераций\n",
    "max_it = 5\n",
    "\n",
    "spellchecker = IterativeSpellChecker(\n",
    "    candidate_generator,\n",
    "    position_selector,\n",
    "    candidate_scorer,\n",
    "    tokenizer,\n",
    "    detokenizer,\n",
    "    ignore_titles=True,\n",
    "    max_it=max_it,\n",
    "    combine_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучающая выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:50:37.199988Z",
     "start_time": "2021-02-17T09:50:37.146504Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(DATA_PATH, 'external', 'spell_ru_eval', 'train_source.txt'), \n",
    "    'r'\n",
    ") as inf:\n",
    "    sentences = inf.readlines()\n",
    "    \n",
    "with open(\n",
    "    os.path.join(DATA_PATH, 'external', 'spell_ru_eval', \n",
    "                 'train_corrected.txt'), \n",
    "    'r'\n",
    ") as inf:\n",
    "    true_sentences = inf.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим наш spell checker, подавая ему предложения батчами размера `batch_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T10:45:48.605235Z",
     "start_time": "2021-02-17T09:50:37.202218Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "sentences_corrected = []\n",
    "num_batches = int(np.ceil(len(sentences) / batch_size))\n",
    "\n",
    "for i in tqdm(range(num_batches)):\n",
    "    cur_sentences = sentences[i*batch_size:(i+1)*batch_size]\n",
    "    sentences_corrected += spellchecker(cur_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем результаты файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T10:45:49.259998Z",
     "start_time": "2021-02-17T10:45:48.611998Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p ../data/processed/results_svm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T11:03:06.709798Z",
     "start_time": "2021-02-17T11:03:06.631039Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'processed', 'results_svm', 'train.txt'), 'w') as ouf:\n",
    "    ouf.writelines([sentence + '\\n' for sentence in sentences_corrected])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним скрит для измерения качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T13:07:25.733166Z",
     "start_time": "2021-02-04T13:07:08.214721Z"
    }
   },
   "outputs": [],
   "source": [
    "!python ../src/evaluation/spell_ru_eval/evaluate.py -d ../data/processed/results_svm/diffs_train.txt ../data/external/spell_ru_eval/train_source.txt ../data/external/spell_ru_eval/train_corrected.txt ../data/processed/results_svm/train.txt | tail -n 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ranking SVM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True Positive: $1311$\n",
    "* Внесенных исправлений: $1451$ \n",
    "* Требуемых исправления: $1727$ \n",
    "* Precision: $90.35$, доверительный интервал: $(88.83, 91.87)$\n",
    "* Recall: $75.91$, доверительный интервал: $(74.63, 77.19)$\n",
    "* FMeasure: $82.50$, доверительный интервал: $(81.11, 83.90)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ranking SVM (с объединением токенов)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True Positive: $1331$\n",
    "* Внесенных исправлений: $1479$ \n",
    "* Требуемых исправления: $1727$ \n",
    "* Precision: $89.99$, доверительный интервал: $(88.47, 91.52)$\n",
    "* Recall: $77.07$, доверительный интервал: $(75.76, 78.38)$\n",
    "* FMeasure: $83.03$, доверительный интервал: $(81.62, 84.44)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ranking SVM (без BERT)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True Positive: $1277$\n",
    "* Внесенных исправлений: $1428$ \n",
    "* Требуемых исправления: $1727$ \n",
    "* Precision: $87.83$, доверительный интервал: $(87.83, 91.02)$\n",
    "* Recall: $73.94$, доверительный интервал: $(72.62, 75.26)$\n",
    "* FMeasure: $80.95$, доверительный интервал: $(79.51, 82.40)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True Positive: $1358$\n",
    "* Внесенных исправлений: $1458$ \n",
    "* Требуемых исправления: $1727$ \n",
    "* Precision: $93.19$, доверительный интервал: $(91.84, 94.44)$\n",
    "* Recall: $78.63$, доверительный интервал: $(77.54, 79.73)$\n",
    "* FMeasure: $85.27$, доверительный интервал: $(84.08, 86.47)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoost (с объединением токенов)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True Positive: $1385$\n",
    "* Внесенных исправлений: $1495$ \n",
    "* Требуемых исправления: $1727$ \n",
    "* Precision: $92.64$, доверительный интервал: $(91.32, 93.97)$\n",
    "* Recall: $80.20$, доверительный интервал: $(79.05, 81.34)$\n",
    "* FMeasure: $85.95$, доверительный интервал: $(84.74, 87.20)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoost (без BERT)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True Positive: $1324$\n",
    "* Внесенных исправлений: $1454$ \n",
    "* Требуемых исправления: $1727$ \n",
    "* Precision: $91.06$, доверительный интервал: $(89.59, 92.53)$\n",
    "* Recall: $76.66$, доверительный интервал: $(75.43, 77.90)$\n",
    "* FMeasure: $83.24$, доверительный интервал: $(81.90, 84.59)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестовая выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T11:05:33.338241Z",
     "start_time": "2021-02-17T11:05:33.221739Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(DATA_PATH, 'external', 'spell_ru_eval', 'test_source.txt'), \n",
    "    'r'\n",
    ") as inf:\n",
    "    sentences = inf.readlines()\n",
    "    \n",
    "with open(\n",
    "    os.path.join(DATA_PATH, 'external', 'spell_ru_eval', \n",
    "                 'test_corrected.txt'), \n",
    "    'r'\n",
    ") as inf:\n",
    "    true_sentences = inf.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим наш spell checker, подавая ему предложения батчами размера `batch_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T12:15:14.188297Z",
     "start_time": "2021-02-17T11:05:35.817922Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "sentences_corrected = []\n",
    "num_batches = int(np.ceil(len(sentences) / batch_size))\n",
    "\n",
    "for i in tqdm(range(num_batches)):\n",
    "    cur_sentences = sentences[i*batch_size:(i+1)*batch_size]\n",
    "    sentences_corrected += spellchecker(cur_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем результаты файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T14:12:50.303403Z",
     "start_time": "2021-02-04T14:12:50.080101Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'processed', 'results_svm', 'test.txt'), 'w') as ouf:\n",
    "    ouf.writelines([sentence + '\\n' for sentence in sentences_corrected])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним скрит для измерения качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T08:00:56.798084Z",
     "start_time": "2021-02-08T08:00:33.850720Z"
    }
   },
   "outputs": [],
   "source": [
    "!python ../src/evaluation/spell_ru_eval/evaluate.py -d ../data/processed/results_svm/diffs_test.txt ../data/external/spell_ru_eval/test_source.txt ../data/external/spell_ru_eval/test_corrected.txt ../data/processed/results_svm/test.txt | tail -n 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ranking SVM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True Positive: $1393$\n",
    "* Внесенных исправлений: $1596$ \n",
    "* Требуемых исправления: $1976$ \n",
    "* Precision: $87.28$, доверительный интервал: $(85.66, 88.91)$\n",
    "* Recall: $70.50$, доверительный интервал: $(69.18, 71.81)$\n",
    "* FMeasure: $78.00$, доверительный интервал: $(76.54, 79.45)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ranking SVM (с объединением токенов)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True Positive: $1438$\n",
    "* Внесенных исправлений: $1648$ \n",
    "* Требуемых исправления: $1976$ \n",
    "* Precision: $87.26$, доверительный интервал: $(85.64, 88.87)$\n",
    "* Recall: $72.77$, доверительный интервал: $(71.42, 74.12)$\n",
    "* FMeasure: $79.36$, доверительный интервал: $(77.89, 80.83)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ranking SVM (без BERT)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True Positive: $1348$\n",
    "* Внесенных исправлений: $1566$ \n",
    "* Требуемых исправления: $1976$\n",
    "* Precision: $86.08$, доверительный интервал: $(84.37, 87.79)$\n",
    "* Recall: $68.22$, доверительный интервал: $(66.87, 69.57)$\n",
    "* FMeasure: $76.12$, доверительный интервал: $(74.61, 77.62)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True Positive: $1375$\n",
    "* Внесенных исправлений: $1578$ \n",
    "* Требуемых исправления: $1976$\n",
    "* Precision: $87.14$, доверительный интервал: $(85.48, 88.79)$\n",
    "* Recall: $69.59$, доверительный интервал: $(68.27, 70.90)$\n",
    "* FMeasure: $77.38$, доверительный интервал: $(75.91, 78.84)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoost (с объединением токенов)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True Positive: $1427$\n",
    "* Внесенных исправлений: $1640$ \n",
    "* Требуемых исправления: $1976$\n",
    "* Precision: $87.01$, доверительный интервал: $(85.38, 88.64)$\n",
    "* Recall: $72.22$, доверительный интервал: $(70.86, 73.57)$\n",
    "* FMeasure: $78.93$, доверительный интервал: $(77.45, 80.41)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoost (без BERT)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True Positive: $1346$\n",
    "* Внесенных исправлений: $1569$ \n",
    "* Требуемых исправления: $1976$\n",
    "* Precision: $85.79$, доверительный интервал: $(84.06, 87.51)$\n",
    "* Recall: $68.12$, доверительный интервал: $(66.75, 69.49)$\n",
    "* FMeasure: $75.94$, доверительный интервал: $(74.41, 77.47)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "1. Результаты удалось заметно улучшить и достичь SOTA.\n",
    "2. CatBoost дал улучшение на обучающей выборке, но на тестовой лучше оказалась модель на SVM.\n",
    "3. Модели без признаков BERT показывают результат на $\\approx 1.5\\%$ хуже.\n",
    "4. Добавление объединения токенов улучшает результат на $\\approx 1\\%$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

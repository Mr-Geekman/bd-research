{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Демонстрация Spell Checker\n",
    "\n",
    "В этом ноутбуке будет произведена демонстрация написанной модели на примере нескольких предложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:51:03.984651Z",
     "start_time": "2021-01-16T15:51:03.859210Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:51:07.306763Z",
     "start_time": "2021-01-16T15:51:03.988385Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from string import punctuation\n",
    "sys.path.append('..')\n",
    "\n",
    "import dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertForMaskedLM, BertTokenizer, BertConfig\n",
    "\n",
    "from deeppavlov.models.spelling_correction.levenshtein import (\n",
    "    LevenshteinSearcherComponent\n",
    ")\n",
    "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
    "\n",
    "import kenlm\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "\n",
    "from src.models.SpellChecker.levenshtein_candidate_generator import (\n",
    "    LevenshteinCandidateGenerator\n",
    ")\n",
    "from src.models.SpellChecker.kenlm_position_selector import (\n",
    "    KenlmPositionSelector\n",
    ")\n",
    "from src.models.BertScorer.bert_scorer_correction import (\n",
    "    BertScorerCorrection\n",
    ")\n",
    "from src.models.SpellChecker.bert_candidate_scorer import (\n",
    "    BertCandidateScorer\n",
    ")\n",
    "from src.models.SpellChecker.margin_stopping_criteria import (\n",
    "    MultiplicativeMarginStoppingCriteria\n",
    ")\n",
    "from src.models.SpellChecker.spell_checker import IterativeSpellChecker\n",
    "\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:51:07.360874Z",
     "start_time": "2021-01-16T15:51:07.310814Z"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_PATH = os.path.join(os.path.abspath(''), os.pardir)\n",
    "CONFIGS_PATH = os.path.join(PROJECT_PATH, 'src', 'configs')\n",
    "os.environ['DP_PROJECT_PATH'] = PROJECT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:51:07.396860Z",
     "start_time": "2021-01-16T15:51:07.365313Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(PROJECT_PATH, 'data')\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с того, что инициализируем все необходимые компоненты модели. Параллельно так же будет описана роль каждого компонента в системе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer/Detokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот компонент отвечает за токенизаци/детокенизацию исходного предложения. В качестве основы было решено взять токенизатор из библиотеки [sacremoses](https://github.com/alvations/sacremoses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:51:07.435340Z",
     "start_time": "2021-01-16T15:51:07.398902Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_tokenizer = MosesTokenizer(lang='ru')\n",
    "raw_detokenizer = MosesDetokenizer(lang='ru')\n",
    "tokenizer = lambda x: raw_tokenizer.tokenize(x)\n",
    "detokenizer = lambda x: raw_detokenizer.detokenize(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот компонент отвечает за то, чтобы генерировать кандидатов для каждой позиции токенизированного предложения. \n",
    "\n",
    "На данный момент берутся слова из словаря на заданном расстоянии Дамерау-Левенштейна от исходного токена. Иногда эти слова еще разбиваются пробелами.\n",
    "\n",
    "В качестве словаря был взят [этот](https://github.com/danakt/russian-words/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:53:54.073021Z",
     "start_time": "2021-01-16T15:51:07.437337Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-16 18:51:07.477 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/mrgeekman/Documents/MIPT/НИР/Repo/data/external/russian_words/russian_words_vocab.dict]\n"
     ]
    }
   ],
   "source": [
    "vocab_path = os.path.join(DATA_PATH, 'external', 'russian_words', \n",
    "                          'russian_words_vocab.dict')\n",
    "vocab = SimpleVocabulary(load_path=vocab_path, save_path=vocab_path)\n",
    "levenshtein_searcher_component = LevenshteinSearcherComponent(\n",
    "    words=vocab.keys(), max_distance=1\n",
    ")\n",
    "candidate_generator = LevenshteinCandidateGenerator(\n",
    "    levenshtein_searcher_component\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position Selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот компонент отвечает за нахождение оптимальной позиции для замены и предварительный выбор кандидатов для этой позиции.\n",
    "\n",
    "На данный момент берутся две языковые модели: слева-направо и справа-налево, которые работают с текстом без пунктуации. Для каждой позиции по просматривается весь список кандидатов при использовании левого и правого контекстов и подсчитывается log-prob. Если токен состоит из нескольких подтокенов (например, если в слове есть пробел), то скор суммируется.\n",
    "\n",
    "Так как для каждого кандидата имеется два log-prob их результат аггрегируется в некий более удобный положительный скор. На данный момент от каждого log-prob берется функция $-1/x$ и от их результата считается среднее гармоническое.\n",
    "\n",
    "Так же мы знаем какой из кандидатов в каждой позиции соответствует изначальному токену (он обязательно там есть) и скор каждого кандидата с ним сравнивается.\n",
    "\n",
    "Выбранная позиция для изменения -- та, у которой наибольшее отношение максимального скора к скору текущего токена. На основе этого отношени так же отбирается предварительный список кандидатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:54:14.474846Z",
     "start_time": "2021-01-16T15:53:54.075771Z"
    }
   },
   "outputs": [],
   "source": [
    "model_left_right = kenlm.LanguageModel(\n",
    "    os.path.join(MODEL_PATH, 'kenlm', 'left_right.arpa.binary')\n",
    ")\n",
    "model_right_left = kenlm.LanguageModel(\n",
    "    os.path.join(MODEL_PATH, 'kenlm', 'right_left.arpa.binary')\n",
    ")\n",
    "position_selector = KenlmPositionSelector(model_left_right, model_right_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот компонент отвечает за выбор наилучшего кандидата из списка предложенных position selector.\n",
    "\n",
    "На данный момент берется модель [Conversational RuBERT](http://docs.deeppavlov.ai/en/master/features/models/bert.html). В первую очередь токенизируется (WordPiece) исходное предложение с MASK-токеном на месте замяемого токена. Хочется просто запустить Masked Language Modeling и попробовать поподставлять кандидатов вместо MASK, но проблема в том, что некоторые кандидаты состоят из более, чем одного токена. В таком случае мы токенизируем всех кандидатов и пытаемся двигать MASK-токен по каждой позиции внутри него, делая другие позиции UNK-токеном и отключая для них attention (не обязательно ставить UNK-токен, это было сделано для удобства). Для аггрегации log-prob скоров внутри одного кандидата берется сумма. По аналогии с position selector к итоговому скору кандидата применяется $-1/x$.\n",
    "\n",
    "В результате отбиратеся кандидат с наилучшим скором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:54:32.715867Z",
     "start_time": "2021-01-16T15:54:14.497609Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/mrgeekman/Documents/MIPT/НИР/Repo/notebooks/../models/conversational_rubert/pytorch_model.bin were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at /home/mrgeekman/Documents/MIPT/НИР/Repo/notebooks/../models/conversational_rubert/pytorch_model.bin and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "BERT_PATH = os.path.join(MODEL_PATH, 'conversational_rubert')\n",
    "config = BertConfig.from_json_file(\n",
    "    os.path.join(BERT_PATH, 'bert_config.json')\n",
    ")\n",
    "model = BertForMaskedLM.from_pretrained(\n",
    "    os.path.join(BERT_PATH, 'pytorch_model.bin'),\n",
    "    config=config\n",
    ")\n",
    "bert_tokenizer = BertTokenizer(os.path.join(BERT_PATH, 'vocab.txt'))\n",
    "scorer_basis = BertScorerCorrection(model, bert_tokenizer)\n",
    "candidate_scorer = BertCandidateScorer(scorer_basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopping Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот компонент отвечает за остановку итераций исправления.\n",
    "\n",
    "На данный момент берутся скор текущего токена и лучший скор, полученный при помощи BERT. На основе их отношения решается делать следующую итерацию или нет.\n",
    "\n",
    "Если отношение превышает некую константу, то мы продолжаем, иначе останавливаемся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:54:32.787529Z",
     "start_time": "2021-01-16T15:54:32.721744Z"
    }
   },
   "outputs": [],
   "source": [
    "margin_constant = 1.01\n",
    "stopping_criteria = MultiplicativeMarginStoppingCriteria(margin_constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spell Checker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выше были описаны все компоненты модели. Итого, имеем этапы:\n",
    "1. Генерация кандидатов\n",
    "2. Итерации до тех пор, пока не сработает критерий останова или не исчерпается максимальное количество итераций\n",
    "    * Поиск лучшей позиции для исправления и отбор кандидатов для исправления\n",
    "    * Выбор лучшего исправления\n",
    "    * Исправление текущего предложения\n",
    "    * Проверка критерия останова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:54:32.840278Z",
     "start_time": "2021-01-16T15:54:32.792699Z"
    }
   },
   "outputs": [],
   "source": [
    "# количество кандидатов, отбираемых position selector\n",
    "num_selected_candidates = 16\n",
    "# максимальное количество итераций\n",
    "max_it = 5\n",
    "\n",
    "spellchecker = IterativeSpellChecker(\n",
    "    candidate_generator,\n",
    "    position_selector,\n",
    "    candidate_scorer,\n",
    "    stopping_criteria,\n",
    "    tokenizer,\n",
    "    detokenizer,\n",
    "    num_selected_candidates,\n",
    "    max_it\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Демонстрация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем 5 предложений из обучающей части датасета вместе с ответами и посмотрим на результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:54:47.804969Z",
     "start_time": "2021-01-16T15:54:47.737916Z"
    }
   },
   "outputs": [],
   "source": [
    "num_examples = 5\n",
    "\n",
    "with open(\n",
    "    os.path.join(DATA_PATH, 'external', 'spell_ru_eval', 'train_source.txt'), \n",
    "    'r'\n",
    ") as inf:\n",
    "    all_sentences = inf.readlines()\n",
    "    \n",
    "with open(\n",
    "    os.path.join(DATA_PATH, 'external', 'spell_ru_eval', \n",
    "                 'train_corrected.txt'), \n",
    "    'r'\n",
    ") as inf:\n",
    "    all_corrected_sentences = inf.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:54:49.358148Z",
     "start_time": "2021-01-16T15:54:49.274863Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "num_sentences = len(all_sentences)\n",
    "all_indices = np.arange(num_sentences)\n",
    "np.random.shuffle(all_indices)\n",
    "indices = all_indices[:num_examples]\n",
    "\n",
    "examples = [all_sentences[idx].strip() for idx in indices]\n",
    "examples_true = [all_corrected_sentences[idx].strip() for idx in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:54:50.224762Z",
     "start_time": "2021-01-16T15:54:50.116275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1860,  353, 1333,  905, 1289])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:54:51.706343Z",
     "start_time": "2021-01-16T15:54:51.646328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Но стоит ли так быстро поддаваться унынию и пессимистическому настроению?',\n",
       " 'Дооолго шли, солнце уже садится стало, в лесу слышны залпы - тревога в княжестве, ищут нас - беглянок.',\n",
       " 'Ну все седня будут вещать про природные катаклизмы, свои отпуска ( хотя об этом и нельзя писать ) и прочий пазитив.',\n",
       " 'Символизируэт стремление мужчин все в этой жизни делать ради женщин.',\n",
       " 'С людьми уже давно развела жизнь или ты даже и не знаешь их совсем, а тут почти вся их жизнь - словно на ладони, будто интереснейший роман читаешь.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:54:52.091520Z",
     "start_time": "2021-01-16T15:54:52.021166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Но стоит ли так быстро поддаваться унынию и пессимистическому настроению',\n",
       " 'Долго шли солнце уже садиться стало в лесу слышны залпы тревога в княжестве ищут нас беглянок',\n",
       " 'Ну все сегодня будут вещать про природные катаклизмы свои отпуска хотя об этом и нельзя писать и прочий позитив',\n",
       " 'Символизирует стремление мужчин все в этой жизни делать ради женщин',\n",
       " 'С людьми уже давно развела жизнь или ты даже и не знаешь их совсем а тут почти вся их жизнь словно на ладони будто интереснейший роман читаешь']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим наш spell checker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:55:06.668642Z",
     "start_time": "2021-01-16T15:54:53.842420Z"
    }
   },
   "outputs": [],
   "source": [
    "examples_corrected = spellchecker(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:57:10.141682Z",
     "start_time": "2021-01-16T15:57:10.082384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\tНо стоит ли так быстро поддаваться унынию и пессимистическому настроению?\n",
      "Corrected:\tно стоит ли так быстро поддаваться унынию и пессимистическому настроению\n",
      "True:\t\tНо стоит ли так быстро поддаваться унынию и пессимистическому настроению\n",
      "\n",
      "Original:\tДооолго шли, солнце уже садится стало, в лесу слышны залпы - тревога в княжестве, ищут нас - беглянок.\n",
      "Corrected:\tдооолго ли солнце уже садится стало в лесу слышны залпы тревога в княжестве ищут нас беглянок\n",
      "True:\t\tДолго шли солнце уже садиться стало в лесу слышны залпы тревога в княжестве ищут нас беглянок\n",
      "\n",
      "Original:\tНу все седня будут вещать про природные катаклизмы, свои отпуска ( хотя об этом и нельзя писать ) и прочий пазитив.\n",
      "Corrected:\tну все седня будут вещать про природные катаклизмы свои отпуска хотя об этом и нельзя писать и прочий пазитив\n",
      "True:\t\tНу все сегодня будут вещать про природные катаклизмы свои отпуска хотя об этом и нельзя писать и прочий позитив\n",
      "\n",
      "Original:\tСимволизируэт стремление мужчин все в этой жизни делать ради женщин.\n",
      "Corrected:\tсимволизирует стремление мужчин все в этой жизни делать ради женщин\n",
      "True:\t\tСимволизирует стремление мужчин все в этой жизни делать ради женщин\n",
      "\n",
      "Original:\tС людьми уже давно развела жизнь или ты даже и не знаешь их совсем, а тут почти вся их жизнь - словно на ладони, будто интереснейший роман читаешь.\n",
      "Corrected:\tс людьми уже давно развела жизнь или ты даже и не знаешь их совсем а тут почти вся их жизнь словно на ладони будто интереснейший роман читаешь\n",
      "True:\t\tС людьми уже давно развела жизнь или ты даже и не знаешь их совсем а тут почти вся их жизнь словно на ладони будто интереснейший роман читаешь\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_examples):\n",
    "    print(f'Original:\\t{examples[i]}')\n",
    "    print(f'Corrected:\\t{examples_corrected[i]}')\n",
    "    print(f'True:\\t\\t{examples_true[i]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению, исправляется все весьма плохо."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

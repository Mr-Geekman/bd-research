{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование Spell Checker с использованием SVM\n",
    "\n",
    "В этом ноутбуке будет произведено тестировние модели, в которой в candidate scorer используется ranking SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:47:03.199511Z",
     "start_time": "2021-01-28T12:47:03.121242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:47:03.285518Z",
     "start_time": "2021-01-28T12:47:03.248023Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "from string import punctuation\n",
    "sys.path.append('..')\n",
    "\n",
    "import dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertForMaskedLM, BertTokenizer, BertConfig\n",
    "\n",
    "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
    "\n",
    "import kenlm\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "\n",
    "from src.models.SpellChecker import *\n",
    "from src.models.BertScorer.bert_scorer_correction import (\n",
    "    BertScorerCorrection\n",
    ")\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:47:03.416530Z",
     "start_time": "2021-01-28T12:47:03.364244Z"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_PATH = os.path.join(os.path.abspath(''), os.pardir)\n",
    "DATA_PATH = os.path.join(PROJECT_PATH, 'data')\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с того, что инициализируем все необходимые компоненты модели. Параллельно так же будет описана роль каждого компонента в системе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:47:03.778753Z",
     "start_time": "2021-01-28T12:47:03.725898Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_tokenizer = MosesTokenizer(lang='ru')\n",
    "raw_detokenizer = MosesDetokenizer(lang='ru')\n",
    "tokenizer = lambda x: raw_tokenizer.tokenize(x, escape=False)\n",
    "detokenizer = lambda x: raw_detokenizer.detokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:50:00.947214Z",
     "start_time": "2021-01-28T12:47:03.823372Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-28 15:47:03.857 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/mrgeekman/Documents/MIPT/НИР/Repo/data/external/russian_words/russian_words_vocab.dict]\n"
     ]
    }
   ],
   "source": [
    "vocab_path = os.path.join(DATA_PATH, 'external', 'russian_words', \n",
    "                          'russian_words_vocab.dict')\n",
    "vocab = SimpleVocabulary(load_path=vocab_path, save_path=vocab_path)\n",
    "handcode_table_path = os.path.join(DATA_PATH, 'processed', 'handcode_table', \n",
    "                                   'table.json')\n",
    "with open(handcode_table_path, 'r') as inf:\n",
    "    handcode_table = json.load(inf)\n",
    "candidate_generator = CandidateGenerator(\n",
    "    words=vocab.keys(), handcode_table=handcode_table, max_distance=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:50:24.822804Z",
     "start_time": "2021-01-28T12:50:00.950015Z"
    }
   },
   "outputs": [],
   "source": [
    "model_left_right = kenlm.LanguageModel(\n",
    "    os.path.join(MODEL_PATH, 'kenlm', 'left_right_3_100.arpa.binary')\n",
    ")\n",
    "model_right_left = kenlm.LanguageModel(\n",
    "    os.path.join(MODEL_PATH, 'kenlm', 'right_left_3_100.arpa.binary')\n",
    ")\n",
    "position_selector = KenlmPositionSelector(model_left_right, model_right_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:50:41.732325Z",
     "start_time": "2021-01-28T12:50:24.844924Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/mrgeekman/Documents/MIPT/НИР/Repo/notebooks/../models/conversational_rubert/pytorch_model.bin were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at /home/mrgeekman/Documents/MIPT/НИР/Repo/notebooks/../models/conversational_rubert/pytorch_model.bin and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "BERT_PATH = os.path.join(MODEL_PATH, 'conversational_rubert')\n",
    "config = BertConfig.from_json_file(\n",
    "    os.path.join(BERT_PATH, 'bert_config.json')\n",
    ")\n",
    "model = BertForMaskedLM.from_pretrained(\n",
    "    os.path.join(BERT_PATH, 'pytorch_model.bin'),\n",
    "    config=config\n",
    ")\n",
    "bert_tokenizer = BertTokenizer(os.path.join(BERT_PATH, 'vocab.txt'))\n",
    "bert_scorer_correction = BertScorerCorrection(model, bert_tokenizer)\n",
    "agg_subtoken_func = np.mean\n",
    "bert_scorer = BertScorer(\n",
    "    bert_scorer_correction, agg_subtoken_func\n",
    ")\n",
    "\n",
    "with open(os.path.join(DATA_PATH, 'processed', 'scorer_learning', 'svm.bin'), 'rb') as inf:\n",
    "    svm_model = pickle.load(inf)\n",
    "\n",
    "svm_scorer = SVMScorer(svm_model, bert_scorer=bert_scorer)\n",
    "candidate_scorer = CandidateScorer(svm_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:50:41.788198Z",
     "start_time": "2021-01-28T12:50:41.735897Z"
    }
   },
   "outputs": [],
   "source": [
    "stopping_criteria = MarginStoppingCriteria(np.log(2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:50:41.829305Z",
     "start_time": "2021-01-28T12:50:41.791337Z"
    }
   },
   "outputs": [],
   "source": [
    "# максимальное количество итераций\n",
    "max_it = 5\n",
    "\n",
    "spellchecker = IterativeSpellChecker(\n",
    "    candidate_generator,\n",
    "    position_selector,\n",
    "    candidate_scorer,\n",
    "    stopping_criteria,\n",
    "    tokenizer,\n",
    "    detokenizer,\n",
    "    num_selected_candidates=None,\n",
    "    max_it=max_it\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:50:41.888013Z",
     "start_time": "2021-01-28T12:50:41.831673Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(DATA_PATH, 'external', 'spell_ru_eval', 'train_source.txt'), \n",
    "    'r'\n",
    ") as inf:\n",
    "    sentences = inf.readlines()\n",
    "    \n",
    "with open(\n",
    "    os.path.join(DATA_PATH, 'external', 'spell_ru_eval', \n",
    "                 'train_corrected.txt'), \n",
    "    'r'\n",
    ") as inf:\n",
    "    true_sentences = inf.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим наш spell checker, подавая ему предложения батчами размера `batch_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T14:33:05.051721Z",
     "start_time": "2021-01-28T13:08:00.656094Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3412b77058ad4291a452ec40e9cfcd3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "sentences_corrected = []\n",
    "num_batches = int(np.ceil(len(sentences) // batch_size))\n",
    "\n",
    "for i in tqdm(range(num_batches)):\n",
    "    cur_sentences = sentences[i*batch_size:(i+1)*batch_size]\n",
    "    sentences_corrected += spellchecker(cur_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем результаты файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T14:33:29.802654Z",
     "start_time": "2021-01-28T14:33:29.278676Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p ../data/processed/results_svm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T14:33:30.524762Z",
     "start_time": "2021-01-28T14:33:30.442703Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'processed', 'results_svm', 'validation.txt'), 'w') as ouf:\n",
    "    ouf.writelines([sentence + '\\n' for sentence in sentences_corrected])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним скрит для измерения качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T14:33:38.875515Z",
     "start_time": "2021-01-28T14:33:31.290748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision=90.36 Recall=75.45 FMeasure=82.23\r\n",
      "1303 1442 1727\r\n"
     ]
    }
   ],
   "source": [
    "!python ../src/evaluation/spell_ru_eval/evaluate.py -d ../data/processed/results_svm/diffs_validation.txt ../data/external/spell_ru_eval/train_source.txt ../data/external/spell_ru_eval/train_corrected.txt ../data/processed/results_svm/validation.txt | tail -n 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, имеем\n",
    "* True Positive: $1303$\n",
    "* Внесенных исправлений: $1442$ \n",
    "* Требуемых исправления: $1727$ \n",
    "* Precision: $90.36$\n",
    "* Recall: $75.45$\n",
    "* FMeasure: $82.23$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T14:35:43.015861Z",
     "start_time": "2021-01-28T14:35:42.911582Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(DATA_PATH, 'external', 'spell_ru_eval', 'test_source.txt'), \n",
    "    'r'\n",
    ") as inf:\n",
    "    sentences = inf.readlines()\n",
    "    \n",
    "with open(\n",
    "    os.path.join(DATA_PATH, 'external', 'spell_ru_eval', \n",
    "                 'test_corrected.txt'), \n",
    "    'r'\n",
    ") as inf:\n",
    "    true_sentences = inf.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим наш spell checker, подавая ему предложения батчами размера `batch_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T15:54:52.711756Z",
     "start_time": "2021-01-28T14:35:45.650825Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509d34ef47c7421ab7febfd50dc47735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=401.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "sentences_corrected = []\n",
    "num_batches = int(np.ceil(len(sentences) // batch_size))\n",
    "\n",
    "for i in tqdm(range(num_batches)):\n",
    "    cur_sentences = sentences[i*batch_size:(i+1)*batch_size]\n",
    "    sentences_corrected += spellchecker(cur_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем результаты файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T15:59:31.502659Z",
     "start_time": "2021-01-28T15:59:31.440583Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'processed', 'results_base', 'test.txt'), 'w') as ouf:\n",
    "    ouf.writelines([sentence + '\\n' for sentence in sentences_corrected])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним скрит для измерения качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T15:59:41.901061Z",
     "start_time": "2021-01-28T15:59:31.976808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision=85.78 Recall=66.38 FMeasure=74.84\r\n",
      "1309 1526 1972\r\n"
     ]
    }
   ],
   "source": [
    "!python ../src/evaluation/spell_ru_eval/evaluate.py -d ../data/processed/results_base/diffs_test.txt ../data/external/spell_ru_eval/test_source.txt ../data/external/spell_ru_eval/test_corrected.txt ../data/processed/results_base/test.txt | tail -n 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, имеем\n",
    "* True Positive: $1309$\n",
    "* Внесенных исправлений: $1526$ \n",
    "* Требуемых исправления: $1972$ \n",
    "* Precision: $85.78$\n",
    "* Recall: $66.38$\n",
    "* FMeasure: $74.84$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что на тесте качество падает, но это ожидаемо по результатам участников соревнования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "1. Результаты удалось заметно улучшить и достичь практически SOTA.\n",
    "2. Теперь precision выглядит особенно хорошо и имеет смысл поработать над recall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

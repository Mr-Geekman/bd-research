{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поиск слэнговых ошибок\n",
    "\n",
    "В этом ноутбуке будет произведен поиск слэнговых ошибок для добавления кандидатов в ручном режиме. Под слэнговыми ошибками подразумеваются ошибки делаемые в неформальном общении в соцсетях. К ним не относятся слэнговые сокращения из разряда: \"программа\" -> \"прога\". \n",
    "\n",
    "Дело в том, что некоторые такие ошибки находятся на достаточно большом расстоянии Дамерау-Левенштейна от исходного слова, а потому их весьма сложно исправить. Некоторые из этих слов являются достаточно частыми и можно попробовать выделить и исправить наиболее частые из них.\n",
    "\n",
    "В качестве корпуса со слэнгом возьмем данные из социальных сетей корпуса Тайга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T19:14:14.914978Z",
     "start_time": "2021-02-21T19:14:14.891033Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T19:14:18.253766Z",
     "start_time": "2021-02-21T19:14:14.918441Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "sys.path.append('..')\n",
    "\n",
    "import dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "\n",
    "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
    "\n",
    "from src.models.SpellChecker import LevenshteinSearcher\n",
    "\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T19:14:18.307340Z",
     "start_time": "2021-02-21T19:14:18.256647Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mrgeekman/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T19:14:18.351274Z",
     "start_time": "2021-02-21T19:14:18.311403Z"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_PATH = os.path.join(os.path.abspath(''), os.pardir)\n",
    "DATA_PATH = os.path.join(PROJECT_PATH, 'data')\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подсчет несловарных слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала просто загрузим все данные и для каждого несловарного слова подсчитаем его частоту. В дальнейшем из этого списка можно удалить слова, которые легко исправляются (например, если есть исправление на расстоянии Дамерау-Левенштейна, равном единице)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим токенизаторы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T19:14:18.392298Z",
     "start_time": "2021-02-21T19:14:18.355128Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_tokenizer = MosesTokenizer(lang='ru')\n",
    "raw_detokenizer = MosesDetokenizer(lang='ru')\n",
    "tokenizer = lambda x: raw_tokenizer.tokenize(x, escape=False)\n",
    "detokenizer = lambda x: raw_detokenizer.detokenize(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проинициализируем словарь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T19:14:20.946005Z",
     "start_time": "2021-02-21T19:14:18.396569Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_path = os.path.join(\n",
    "    DATA_PATH, 'external', 'hagen_wiktionary', 'wordforms_clear.txt'\n",
    ")\n",
    "\n",
    "with open(vocab_path, 'r') as inf:\n",
    "    vocab = {\n",
    "        word.strip().lower().replace('ё', 'е') for word in inf.readlines()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T19:14:20.986386Z",
     "start_time": "2021-02-21T19:14:20.948701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 2360221\n"
     ]
    }
   ],
   "source": [
    "print(f'Размер словаря: {len(vocab)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявим список символов, из которых может состоять слово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T19:14:21.033524Z",
     "start_time": "2021-02-21T19:14:20.992229Z"
    }
   },
   "outputs": [],
   "source": [
    "alphabet = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T19:24:17.929286Z",
     "start_time": "2021-02-21T19:14:21.037166Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d03d4e47c94bd3a2d26d32723fcd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2891609.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(DATA_PATH, 'processed', 'kenlm', \n",
    "                         'social_left_right.txt')\n",
    "oov_counter = Counter()\n",
    "\n",
    "with open(file_path, 'r') as inf:\n",
    "    line_numbers = sum(1 for _ in inf)\n",
    "\n",
    "with open(file_path, 'r') as inf:\n",
    "\n",
    "    for sentence in tqdm(inf, total=line_numbers):\n",
    "        tokenized_sentence = tokenizer(sentence)\n",
    "        for word in tokenized_sentence:\n",
    "            if (\n",
    "                not re.fullmatch(f'[{punctuation}]+', word) \n",
    "                and re.fullmatch(f'[{alphabet}]+', word)\n",
    "                and word not in vocab\n",
    "            ):\n",
    "                oov_counter[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на размер получившегося словаря:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T19:24:17.977104Z",
     "start_time": "2021-02-21T19:24:17.931197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter size: 394514\n"
     ]
    }
   ],
   "source": [
    "print(f'Counter size: {len(oov_counter)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выглядит весьма внушительно. Посмотрим на самые популярные слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T19:24:18.172718Z",
     "start_time": "2021-02-21T19:24:17.979631Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('едро', 9181),\n",
       " ('все-таки', 6797),\n",
       " ('з', 4341),\n",
       " ('че', 4085),\n",
       " ('праймериз', 4015),\n",
       " ('чо', 3910),\n",
       " ('жирик', 3744),\n",
       " ('що', 3570),\n",
       " ('гд', 2615),\n",
       " ('щас', 2602)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov_counter.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь создадим соответствие между несловарными словами и их исправлениями. Было проверено чуть больше 5000 слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T19:24:18.234500Z",
     "start_time": "2021-02-21T19:24:18.177043Z"
    }
   },
   "outputs": [],
   "source": [
    "handcode_table = {\n",
    "    'че': ['что'],\n",
    "    'чо': ['что'],\n",
    "    'шо': ['что'],\n",
    "    'ваще': ['вообще'],\n",
    "    'ща': ['сейчас'],\n",
    "    'щас': ['сейчас'],\n",
    "    'оч': ['очень'],\n",
    "    'ничо': ['ничего'],\n",
    "    'ниче': ['ничего'],\n",
    "    'мож': ['может'],\n",
    "    'итд': ['и т.д.'],\n",
    "    'чота': ['что-то'],\n",
    "    'счас': ['сейчас'],\n",
    "    'шоб': ['чтобы', 'чтоб', 'что бы', 'что б'],\n",
    "    'щоб': ['чтобы', 'чтоб', 'что бы', 'что б'],\n",
    "    'штоле': ['что ли'],\n",
    "    'тя': ['тебя'],\n",
    "    'пасиб': ['спасибо'],\n",
    "    'чтоль': ['что ли'],\n",
    "    'седня': ['сегодня'],\n",
    "    'кста': ['кстати'],\n",
    "    'какбэ': ['как бы'],\n",
    "    'чето': ['что-то'],\n",
    "    'этож': ['это же'],\n",
    "    'вапще': ['вообще'],\n",
    "    'хошь': ['хочешь'],\n",
    "    'чтоле': ['что ли'],\n",
    "    'кароч': ['короче'],\n",
    "    'какой-нить': ['какой-нибудь'],\n",
    "    'моск': ['мозг'],\n",
    "    'щаз': ['сейчас'],\n",
    "    'шта': ['что'],\n",
    "    'низзя': ['нельзя'],\n",
    "    'собсно': ['собственно'],\n",
    "    'канешна': ['конечно'],\n",
    "    'чесслово': ['честное слово'],\n",
    "    'напр': ['например'],\n",
    "    'ессно': ['естественно'],\n",
    "    'что-нить': ['что-нибудь'],\n",
    "    'щастье': ['счастье'],\n",
    "    'исчо': ['еще'],\n",
    "    'кагбе': ['как бы'],\n",
    "    'вааще': ['вообще'],\n",
    "    'как-нить': ['как-нибудь'],\n",
    "    'пасиба': ['спасибо'],\n",
    "    'ишшо': ['еще'],\n",
    "    'низя': ['нельзя'],\n",
    "    'аффтар': ['автор'],\n",
    "    'канешн': ['конечно'],\n",
    "    'чойта': ['что это'],\n",
    "    'какбе': ['как бы'],\n",
    "    'када': ['когда'],\n",
    "    'ещо': ['еще'],\n",
    "    'всм': ['в смысле'],\n",
    "    'где-нить': ['где-нибудь'],\n",
    "    'йому': ['ему'],\n",
    "    'кагбэ': ['как бы'],\n",
    "    'прально': ['правильно'],\n",
    "    'неск': ['несколько'],\n",
    "    'штоль': ['что ли'],\n",
    "    'енто': ['это'],\n",
    "    'чо-то': ['что-то'],\n",
    "    'всеж': ['все же'],\n",
    "    'штоб': ['чтобы', 'чтоб', 'что бы', 'что б'],\n",
    "    'шото': ['что-то'],\n",
    "    'есличо': ['если что'],\n",
    "    'нравиццо': ['нравится'],\n",
    "    'соотв': ['соответственно'],\n",
    "    'куда-нить': ['куда-нибудь'],\n",
    "    'тыж': ['ты же'],\n",
    "    'канешно': ['конечно'],\n",
    "    'товарисч': ['товарищ'],\n",
    "    'терь': ['теперь'],\n",
    "    'щетаю': ['считаю'],\n",
    "    'ищо': ['еще'],\n",
    "    'карочи': ['короче'],\n",
    "    'собссно': ['собственно'],\n",
    "    'ни-че-го': ['ничего'],\n",
    "    'штоли': ['что ли'],\n",
    "    'естессно': ['естественно'],\n",
    "    'врятли': ['вряд ли'],\n",
    "    'собсна': ['собственно'],\n",
    "    'грят': ['говорят'],\n",
    "    'тч': ['т.ч.'],\n",
    "    'хош': ['хочешь'],\n",
    "    'ктож': ['кто же'],\n",
    "    'вощем': ['в общем'],\n",
    "    'весчь': ['вещь'],\n",
    "    'щастья': ['счастья'],\n",
    "    'пжлст': ['пожалуйста'],\n",
    "    'щяс': ['сейчас'],\n",
    "    'ченить': ['что-нибудь'],\n",
    "    'че-нить': ['что-нибудь'],\n",
    "    'чоуж': ['что уж'],\n",
    "    'такшта': ['так что'],\n",
    "    'кого-нить': ['кого-нибудь'],\n",
    "    'хоцца': ['хочется'],\n",
    "    'ващще': ['вообще'],\n",
    "    'кто-нить': ['кто-нибудь'],\n",
    "    'вопщем': ['в общем'],\n",
    "    'чево': ['чего'],\n",
    "    'щитаю': ['считаю'],\n",
    "    'есчо': ['еще'],\n",
    "    'какую-нить': [''],\n",
    "    'ящитаю': ['я считаю'],\n",
    "    'мильон': ['миллион'],\n",
    "    'буит': ['будет'],\n",
    "    'смари': ['смотри'],\n",
    "    'штоп': ['чтобы', 'чтоб', 'что бы', 'что б'],\n",
    "    'помойму': ['по-мойму'],\n",
    "    'шо-то': ['что-то'],\n",
    "    'низачот': ['незачет'],\n",
    "    'товарисчи': ['товарищи'],\n",
    "    'чейта': ['что это'],\n",
    "    'пожалста': ['пожалуйста'],\n",
    "    'писят': ['пятьдесят'],\n",
    "    'че-т': ['что-то'],\n",
    "    'хочут': ['хотят'],\n",
    "    'нащот': ['насчет'],\n",
    "    'ващето': ['вообще-то'],\n",
    "    'иво': ['его'],\n",
    "    'мущщина': ['мужчина'],\n",
    "    'щастя': ['счастье', 'счастья'],\n",
    "    'пасип': ['спасибо'],\n",
    "    'непричем': ['ни при чем'],\n",
    "    'воще': ['вообще'],\n",
    "    'фтопку': ['в топку'],\n",
    "    'пжалста': ['пожалуйста'],\n",
    "    'немношк': ['немножко'],\n",
    "    'мущина': ['мужчина'],\n",
    "    'пейсатель': ['писатель'],\n",
    "    'абажаю': ['обожаю'],\n",
    "    'какойта': ['какой-то'],\n",
    "    'аффтор': ['автор'],\n",
    "    'аццкий': ['адский'],\n",
    "    'такшто': ['так что'],\n",
    "    'любофф': ['любовь']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После наблюдения за валидацией также обнаружилось, что подобные сокращения существуют и для словарных слов, добавим то, что удалось найти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T19:24:18.270161Z",
     "start_time": "2021-02-21T19:24:18.236494Z"
    }
   },
   "outputs": [],
   "source": [
    "handcode_table.update({\n",
    "    'тока': ['только'],\n",
    "    'скока': ['сколько']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим еще пару сокращений, которые известны:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T19:25:44.890710Z",
     "start_time": "2021-02-21T19:25:44.829630Z"
    }
   },
   "outputs": [],
   "source": [
    "handcode_table.update({\n",
    "    'кмк': ['как мне кажется'],\n",
    "    'неоч': ['не очень'],\n",
    "    'кст': ['кстати']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на итоговый размер таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T19:25:45.222615Z",
     "start_time": "2021-02-21T19:25:45.188794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер таблицы: 142\n"
     ]
    }
   ],
   "source": [
    "print(f'Размер таблицы: {len(handcode_table)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним ее на диск:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T19:25:45.928627Z",
     "start_time": "2021-02-21T19:25:45.883382Z"
    }
   },
   "outputs": [],
   "source": [
    "handcode_table_path = os.path.join(DATA_PATH, 'processed', 'handcode_table', \n",
    "                                   'table.json')\n",
    "with open(handcode_table_path, 'w') as ouf:\n",
    "    json.dump(handcode_table, ouf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "В этом ноутбуке нам удалось найти ошибки, которые часто совершаются пользователями соцсетей и собрать из этого таблицу с исправлениями."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

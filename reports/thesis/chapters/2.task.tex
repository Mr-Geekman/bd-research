\chapter{Формальная постановка задачи}

Для конкретизации решаемой задачи было выбрано соревнование SpellRuEval --- это одна из дорожек, предложенных участникам конференции <<Диалог 2016>>. В состязании предлагалось исправлять опечатки и грамматические ошибки в текстах из социальных медиа.

\section{Виды ошибок}

\subsection{Классификация с точки зрения языкознания}

Для начала обозначим какие виды ошибок в русскоязычных текстах нам могут быть интересны с точки зрения языкознания:
\begin{enumerate}
	\item Грамматическая ошибка --- это ошибка, связанная с нарушением закономерностей и правил грамматики. К таким ошибкам относятся неправильное образование и употребление форм слова, неверное построение словосочетаний и предложений. \cite{GrammarErrorDefinition}
	\item Орфографическая ошибка --- это неправильное написание слова. Она может быть допущена только на письме, обычно в слабой фонетической позиции. Такую ошибку можно только увидеть, но услышать ее нельзя.
	\item Опечатка --- это ошибка в печатном тексте, обычно в результате случайности.
\end{enumerate}

\subsection{Классификация по словарности}

Можно также выделить несловарные (non-word) и словарные (real-word) ошибки. Первый тип характеризуется тем, что получившееся в результате опечатки слово не является словарным, во втором случае получается словарное слово. Исправлять ошибки первого типа проще. Во-первых, их проще обнаружить, достаточно проверять слова на присутствие в большом словаре. Во-вторых, для их исправления может не понадобиться знание контекста. Ошибки второго типа без понимания контекста исправить нельзя.

\subsection{Классификация по типу преобразования}

Если рассматривать процесс исправления ошибок, то можно выделить различные типы преобразований по тому, как они действуют на смежные слова:
\begin{itemize}
	\item <<один к одному>> --- одно слово заменяется на какое-то другое слово (\textit{лчше} $\rightarrow$ \textit{лучше});
	\item <<один ко многим>> --- одно слово заменяется на несколько слов (\textit{вобщем} $\rightarrow$ \textit{в общем});
	\item <<многие к одному>> --- несколько слов заменяется на одно слово (\textit{как то} $\rightarrow$ \textit{как-то});
	\item <<многие ко многим>> --- несколько слов заменяются на несколько других слов (\textit{вообщем то} $\rightarrow$ \textit{в общем-то}).
\end{itemize}

\section{Обучающее и тестовое множества}

Начнем с рассмотрения предложенных обучающих и тестовых примеров и способа их сбора. Согласно статье \cite{Sorokin2016a}, посвященной соревнованию, организаторы использовали тексты из ГИКРЯ, собранные на блог-платформе <<Живой Журнал>> (\url{https://www.livejournal.com/}). Было автоматически отобрано около 10000 предложений, содержащих несловарные слова. Собранное множество было дополнено несколькими сотнями предложений, содержащих ошибки некорректного употребления словарных слов (real-word errors).  Затем все предложения были перепроверены на предмет содержания ошибок, могло так оказаться, что несловарными были редкие имена, сленговые слова или неологизмы. Итого, было собрано около 5000 предложений.

После этого предложения были направлены разметчикам, которые должны были исправить ошибки и, в случае возникновения трудностей, написать комментарий организаторам. Приведем инструкцию, выданную разметчикам:

Что надо исправлять:
\begin{itemize}
	\item опечатки: \textit{мнея} $\rightarrow$ \textit{меня};
	\item орфографические ошибки: \textit{митель} $\rightarrow$ \textit{метель};
	\item смысловые ошибки: \textit{компания} $\rightarrow$ \textit{кампания};
	\item намеренно неправильное написание: \textit{хоцца} $\rightarrow$ \textit{хочется}, \textit{ваще} $\rightarrow$ \textit{вообще};
	\item грамматические ошибки (согласование): \textit{он видят} $\rightarrow$ \textit{он видит};
	\item ошибки с пробелами/дефисами: \textit{както} $\rightarrow$ \textit{как-то};
	\item смешанное использование чисел и букв в числительных: \textit{2-ух} $\rightarrow$ \textit{двух};
	\item использование цифр вместо букв: \textit{в4ера} $\rightarrow$ \textit{вчера}.
\end{itemize}

Что не надо исправлять:
\begin{itemize}
	\item иностранные слова, включая кириллицу;
	\item неформальные сокращения: \textit{прога} $\rightarrow$ \textit{программа};
	\item пунктуационные ошибки;
	\item ошибки, связанные с заглавным/строчным написанием;
	\item неразличение букв <<е>> и <<ё>>.
\end{itemize}

По словам организаторов, большинство сложных случаев для исправления составляли разговорные формы слов, такие как <<ваще>> вместо <<вообще>> и <<щас>> вместо <<сейчас>>. В большинстве случаев их можно было заменить на литературную форму без потери смысла. Исключения составляли некоторые выражения для экспрессии, такие как <<Ну ты ваще>>, <<Да щас!>>, где замена на литературную форму делает выражение неупотребимым в том же контексте. Ввиду сложностей различения ситуаций, когда замена возможна, а когда невозможна, было решено во всех случаях приводить слова к литературной форме.

Видим, что все рассматриваемые ошибки являются локальными, то есть затрагивают смежные слова. Более сложные грамматические ошибки не рассматриваются. В таком случае бывает весьма сложно понять совершает человек опечатку, орфографическую ошибку или грамматическую ошибку. В тексте ниже мы не будем различать эти понятия, если на этом не будет сакцентированно внимание. 

После полной разметки осталось порядка 2400 исправленных предложений, в которые добавили 1600 корректно написанных предложений. Затем итоговые 4000 предложений разделили пополам на обучающее множество и тестовое.

\subsection{Статистика по обучающему множеству}

Изучим статистику по обучающему множеству.
\begin{itemize}
	\item Количество предложений: 2000.
	\item Количество исправлений: 1727.
	\item Распределение количества ошибок в предложениях:
	\begin{itemize}
		\item 0: 40.6\%;
		\item 1: 40.1\%;
		\item 2: 14.0\%;
		\item 3: 4.0\%;
		\item \geq 4: 1.4\%.
	\end{itemize}
	\item Распределение ошибок по типу преобразования:
	\begin{itemize}
		\item <<один к одному>>: 80.0\%;
		\item <<один ко многим>>: 15.6\%;
		\item <<многие к одному>>: 4.1\%;
		\item <<многие ко многим>>: 0.2\%;
	\end{itemize}
	\item Распределение ошибок по расстоянию Дамерау-Левенштейна \cite{Damerau1964} \cite{Levenshtein1965}:
	\begin{itemize}
		\item 1: 77.2\%;
		\item 2: 15.5\%;
		\item 3: 4.6\%;
		\item \geq 4: 2.7\%;
	\end{itemize}
	\item Количество уникальных исправлений, неизвестных словарю: 68.
\end{itemize}

Такая же статистика для тестового множества не вычислялась для минимизации утечки информации. Кроме того, оказалось, что в итоговом файле было не 2000 тестовых предложений, а 2008.

\section{Оценка качества}

Теперь, когда обучающее и тестовое множества определены, надо понять принципы, на основе которых будет оцениваться качество моделей. Авторы соревнования решили оценивать модель на основе индивидуальных исправлений, то есть основной единицей в измерении качества будет не целое предложение, а отдельные исправления, которых в предложении может быть несколько. В таком случае, возникает проблема выравнивания. В самом деле, чтобы оценивать правильность отдельных исправлений надо понимать какие токены исходного предложения переходят в токены исправленного, что может быть непросто если нет соответствия вида <<один к одному>>. Например, в исходном предложении может быть написано <<кто то>> вместо <<кто-то>> или <<итак>> вместо <<и так>>.

Опишем используемую процедуру выравнивания:
\begin{enumerate}
	\item Предобработка текста, включающая в себя перевод всего текста в нижний регистр.
	\item Токенизация. Организаторы предпочли использовать свой алгоритм, а не один из стандартных. Алгоритм:
	\begin{enumerate}
		\item Разделение слов по пробелам.
		\item Удаление изолированных знаков препинания.
		\item Удаление знаков препинания на краях оставшихся токенов. Например, запятых на концах слов.
	\end{enumerate}
	\item Процедура выравнивания между предобработанными предложениями:
	\begin{enumerate}
		\item При помощи динамического программирования находится наибольшая общая подпоследовательность на уровне слов. Токены, находящиеся на одинаковых позициях в этой подпоследовательности, считаются соответствующими друг другу.
		\item Группы токенов, располагающиеся между выровненными на предыдущем шаге, выравниваются раздельно в соответствии со своими позициями. Для этого строятся переходы согласно расстоянию Дамерау-Левенштейна. Точками выравнивания в таком случае считаются соответствующие друг другу пробелы.
	\end{enumerate}
\end{enumerate}

Рассмотрим работу процедуры на примере из статьи, посвященном соревнованию. В качестве исходного предложения рассмотрим: <<помоему кто то из них то же ошипся>>, а в качестве исправления: <<по-моему кто-то из них тоже ошибся>>.  После выполнения первого этапа выравнивания получим следующие соответствия:

\begin{itemize}
	\item <<помоему кто то>> $\rightarrow$ <<по-моему кто-то>>,
	\item <<из>> $\rightarrow$ <<из>>,
	\item <<них>> $\rightarrow$ <<них>>,
	\item <<то же ошипся>> $\rightarrow$ <<тоже ошибся>>.
\end{itemize}

Во время выполнения второго этапа удастся установить дополнительные соответствия:

\begin{itemize}
	\item <<помоему>> $\rightarrow$ <<по-моему>>,
	\item <<кто то>> $\rightarrow$ <<кто-то>>,
	\item <<то же>> $\rightarrow$ <<тоже>>,
	\item <<ошипся>> $\rightarrow$ <<ошибся>>.
\end{itemize}

После выполнения процедуры выравнивания можно выделить такую сущность, как исправление --- это нетождественное преобразование между элементарными единицами выравнивания в исходном и преобразованном предложениях. Обозначим множество исправлений между исходными и скорректированными моделью предложениями, как $S_{sol}$. Аналогично, для исходных и эталонных предложений --- $S_{cor}$. Теперь можем посчитать следующие метрики:
\begin{gather*}
	P = \frac{\vert S_{cor} \cap S_{sol} \vert}{\vert S_{sol} \vert},
	\\
	R = \frac{\vert S_{cor} \cap S_{sol} \vert}{\vert S_{cor} \vert}.
\end{gather*}

Рассмотрим метрики по отдельности. Метрика $P$ обозначает точность (precision), она показывает, как много исправлений из тех, что выполнила модель, являются корректными. Ее недостаток в том, что она не позволяет понять какую общую долю ошибок модели удалось исправить. Так, например, для получения большой точности можно было бы выполнять только те исправления, в которых велика уверенность.

Метрика $R$ --- это полнота (recall), ее смысл в том, чтобы показать общую долю исправленных ошибок. Тем не менее, она не позволяет увидеть как часто исправления выполнялись там, где исправлять не надо было.

В качестве итоговой метрики было взято среднее гармоническое полноты и точности, которое называется $F$-мерой (или $F_1$-мерой):

\begin{equation*}
	F_1 = \frac{2PR}{P + R}.
\end{equation*}

Такая агрегация позволяет сглаженно реагировать на слишком малое значение одной из метрик.

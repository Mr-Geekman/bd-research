\chapter{Выводы и перспективы}

Подведем итог проведенного исследования. Была построена модель, которая демонстрирует более высокое качество, чем лучшее решение соревнования SpellRuEval. Несмотря на высокие требования к объему оперативной памяти и вычислительным ресурсам можно выделить несколько применений:
\begin{itemize}
	\item Создание веб-сервиса с API для исправления опечаток, как это сделано в Яндекс.Спеллере. В таком случае клиент не должен будет беспокоиться о требованиях к аппаратной части;
	\item Использование модели для предварительной обработки текстов перед применением других методов, чувствительных к опечаткам. В таком случае временные затраты могут не быть столь критичными.
\end{itemize}

Выделим также направления для будущих исследований, которые кажутся перспективными:
\begin{itemize}
	\item cбор более крупного и современного датасета для задачи (Интернет-сленг достаточно быстро меняется);
	\item использование для ранжирования GPT-3 \cite{Brown2020}, в связи с появлением соответствующей версии модели для русского языка;
	\item дообучение модели BERT, используемой для ранжирования;
	\item увеличение производительности и уменьшение расхода памяти;
	\item увеличение предельного расстояния Дамерау-Левенштейна до двух.
\end{itemize}

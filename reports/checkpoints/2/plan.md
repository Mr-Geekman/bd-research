# Примерный план для контроля

## Название

Исправление опечаток и грамматических ошибок в русскоязычных текстах hello.

## Краткая статистика по датасету

1. Размер.
2. Количество ошибок, количество предложений без ошибок. Среднее количество исправлений на предложение. Максимальное количество исправлений на предложение. (Добавить в EDA)
3. Частоты ошибок one-to-one, many-to-one, one-to-many, many-to-many.
4. Частоты ошибок на разном расстоянии Дамерау-Левенштейна.

## Устройство модели

### Краткое описание цикла исправлений в модели

### Candidate Generator

1. LevenshteinSearcher -- взят из DeepPavlov
2. PhoneticSearcher -- реализован по статье
3. HandcodeSearcher -- собран по "Тайге"
4. Дополнительные признаки -- перечислить
5. Объединение токенов -- про то, что можно объединить токены по пробелам, дефисам

### Position Selector

1. Устройство
   * KenLM
   * Вычисление признаков
   * Критерий останова
2. Обучение KenLM
   * "Тайга", возможно, подробности обучения
3. Неудача с обучением supervised-модели.

### Candidate Scorer

1. BertScorer
   * Как происходит вычисление для кандидатов, состоящих из нескольких токенов.
2. Мотивация для дополнительных признаков -- как получил, что понял, что проблема в качестве
3. Как обучил supervised-модель

## Качество и скорость работы

1. Привести качество модели, основанной только на BERT.
2. Примерная скорость работы моделей.

## Проблемы

1. Большое потребление памяти.
2. Слова на расстоянии Дамерау-Левенштейна, равном двум.

## Планы

1. Испытать новый словарь.
2. Перетестировать все текущие вариации моделей.
3. Посмотреть, можно ли что-то сделать с большим потреблением RAM.
4. Привести в порядок репозиторий и google-диск проекта.

@article{Grundkiewicz2019,
abstract = {Considerable effort has been made to address the data sparsity problem in neural grammatical error correction. In this work, we propose a simple and surprisingly effective unsupervised synthetic error generation method based on confusion sets extracted from a spellchecker to increase the amount of training data. Synthetic data is used to pre-train a Transformer sequence-to-sequence model, which not only improves over a strong baseline trained on authentic error-annotated data, but also enables the development of a practical GEC system in a scenario where little genuine error-annotated data is available. The developed systems placed first in the BEA19 shared task, achieving 69.47 and 64.24 F 0.5 in the restricted and low-resource tracks respectively, both on the W{\&}I+LOCNESS test set. On the popular CoNLL 2014 test set, we report state-of-the-art results of 64.16 M 2 for the submitted system , and 61.30 M 2 for the constrained system trained on the NUCLE and Lang-8 data.},
author = {Grundkiewicz, Roman and Junczys-Dowmunt, Marcin and Heafield, Kenneth},
doi = {10.18653/v1/w19-4427},
file = {:home/mrgeekman/Documents/MIPT/НИР/Papers/Neural Grammatical Error Correction Systems with Unsupervised Pre-training on Synthetic Data.pdf:pdf},
pages = {252--263},
title = {{Neural Grammatical Error Correction Systems with Unsupervised Pre-training on Synthetic Data}},
year = {2019}
}
@article{Sorokin2016,
abstract = {This paper describes an automatic spelling correction system for Russian. The system utilizes information from different levels, using edit distance for candidate search and a combination of weighted edit distance and language model for candidate hypotheses selection. The hypotheses are then reranked by logistic regression using edit distance score, language model score etc. as features. We also experimented with morphological and semantic features but did not get any advantage. Our system has won the first SpellRuEval competition for Russian spell checkers by all the metrics and achieved F1-Measure of 75{\%}.},
author = {Sorokin, A. A. and Shavrina, T. O.},
file = {:home/mrgeekman/Documents/MIPT/НИР/Papers/Русский язык/Automatic spelling correction for russian social media texts.pdf:pdf},
issn = {20757182},
journal = {Komp'juternaja Lingvistika i Intellektual'nye Tehnologii},
keywords = {Automatic spelling correction,Non-word errors,Real-word errors,Russian spellchecking,Social media language,Spelling correction,Spelling correction for Russian,Spelling correction on corpora},
pages = {688--701},
title = {{Automatic spelling correction for Russian social media texts}},
year = {2016}
}
@article{Zhao2019,
abstract = {Neural machine translation systems have become state-of-the-art approaches for Grammatical Error Correction (GEC) task. In this paper, we propose a copy-augmented architecture for the GEC task by copying the unchanged words from the source sentence to the target sentence. Since the GEC suffers from not having enough labeled training data to achieve high accuracy. We pre-train the copy-augmented architecture with a denoising auto-encoder using the unlabeled One Billion Benchmark and make comparisons between the fully pre-trained model and a partially pre-trained model. It is the first time copying words from the source context and fully pretraining a sequence to sequence model are experimented on the GEC task. Moreover, We add token-level and sentence-level multi-task learning for the GEC task. The evaluation results on the CoNLL-2014 test set show that our approach outperforms all recently published state-of-the-art results by a large margin. The code and pre-trained models are released at https://github.com/zhawe01/fairseq-gec.},
archivePrefix = {arXiv},
arxivId = {1903.00138},
author = {Zhao, Wei and Wang, Liang and Shen, Kewei and Jia, Ruoyu and Liu, Jingming},
doi = {10.18653/v1/n19-1014},
eprint = {1903.00138},
file = {:home/mrgeekman/Documents/MIPT/НИР/Papers/Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data.pdf:pdf},
isbn = {9781950737130},
journal = {NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference},
pages = {156--165},
title = {{Improving grammatical error correction via pre-training a copy-augmented architecture with unlabeled data}},
volume = {1},
year = {2019}
}
@article{Rozovskaya2019,
abstract = {Until now, most of the research in grammar error correction focused on English, and the problem has hardly been explored for other languages. We address the task of correcting writing mistakes in morphologically rich languages, with a focus on Russian. We present a corrected and error-tagged corpus of Russian learner writing and develop models that make use of existing state-of-the-art methods that have been well studied for English. Although impressive results have recently been achieved for grammar error correction of non-native English writing, these results are limited to domains where plentiful training data are available. Because annotation is extremely costly, these approaches are not suitable for the majority of domains and languages. We thus focus on methods that use “minimal supervision”; that is, those that do not rely on large amounts of annotated training data, and show how existing minimal-supervision approaches extend to a highly inflectional language such as Russian. The results demonstrate that these methods are particularly useful for correcting mistakes in grammatical phenomena that involve rich morphology.},
author = {Rozovskaya, Alla and Roth, Dan},
doi = {10.1162/tacl_a_00251},
file = {:home/mrgeekman/Documents/MIPT/НИР/Papers/Grammar Error Correction in Morphologically Rich Languages The Case of Russian.pdf:pdf},
issn = {2307-387X},
journal = {Transactions of the Association for Computational Linguistics},
pages = {1--17},
title = {{Grammar Error Correction in Morphologically Rich Languages: The Case of Russian}},
volume = {7},
year = {2019}
}
@article{Awasthi2020,
abstract = {We present a Parallel Iterative Edit (PIE) model for the problem of local sequence transduction arising in tasks like Grammatical error correction (GEC). Recent approaches are based on the popular encoder-decoder (ED) model for sequence to sequence learning. The ED model auto-regressively captures full dependency among output tokens but is slow due to sequential decoding. The PIE model does parallel decoding, giving up the advantage of modelling full dependency in the output, yet it achieves accuracy competitive with the ED model for four reasons: 1. predicting edits instead of tokens, 2. labeling sequences instead of generating sequences, 3. iteratively refining predictions to capture dependencies, and 4. factorizing logits over edits and their token argument to harness pretrained language models like BERT. Experiments on tasks spanning GEC, OCR correction and spell correction demonstrate that the PIE model is an accurate and significantly faster alternative for local sequence transduction. The code and pre-trained models for GEC are available at https://github.com/awasthiabhijeet/PIE.},
archivePrefix = {arXiv},
arxivId = {1910.02893},
author = {Awasthi, Abhijeet and Sarawagi, Sunita and Goyal, Rasna and Ghosh, Sabyasachi and Piratla, Vihari},
doi = {10.18653/v1/d19-1435},
eprint = {1910.02893},
file = {:home/mrgeekman/Documents/MIPT/НИР/Papers/Parallel Iterative Edit Models for Local Sequence Transduction.pdf:pdf},
isbn = {9781950737901},
journal = {EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference},
pages = {4260--4270},
title = {{Parallel iterative edit models for local sequence transduction}},
year = {2020}
}
@article{Flor2012,
abstract = {In this paper we present a new spell-checking system that utilizes contextual information for automatic correction of non-word misspellings. The system is evaluated with a large corpus of essays written by native and nonnative speakers of English to the writing prompts of high-stakes standardized tests (TOEFL{\textregistered} and GRE{\textregistered}). We also present comparative evaluations with Aspell and the speller from Microsoft Office 2007. Using context-informed re-ranking of candidate suggestions, our system exhibits superior errorcorrection results overall and also corrects errors generated by non-native English writers with almost same rate of success as it does for writers who are native English speakers.},
author = {Flor, Michael and Fugati, Yoko},
file = {:home/mrgeekman/Documents/MIPT/НИР/Papers/On using context for automatic correction  of non-word misspellings in student essays.pdf:pdf},
journal = {Proceedings of the 7th workshop on innovative use of {\{}NLP{\}} for {\{}Building{\}} {\{}Educational{\}} {\{}Applications{\}}},
pages = {105--115},
title = {{On using context for automatic correction of non-word misspellings in student essays.}},
url = {http://aclweb.org/anthology/W/W12/W12-2012.pdf},
year = {2012}
}
@article{Flor2019,
abstract = {Spelling correction has attracted a lot of attention in the NLP community. However, models have been usually evaluated on artificiallycreated or proprietary corpora. A publiclyavailable corpus of authentic misspellings, annotated in context, is still lacking. To address this, we present and release an annotated data set of 6,121 spelling errors in context, based on a corpus of essays written by English language learners. We also develop a minimallysupervised context-aware approach to spelling correction. It achieves strong results on our data: 88.12{\{}$\backslash${\%}{\}} accuracy. This approach can also train with a minimal amount of annotated data (performance reduced by less than 1{\{}$\backslash${\%}{\}}). Furthermore, this approach allows easy portability to new domains. We evaluate our model on data from a medical domain and demonstrate that it rivals the performance of a model trained and tuned on in-domain data.},
author = {Flor, Michael and Fried, Michael and Rozovskaya, Alla},
doi = {10.18653/v1/w19-4407},
file = {:home/mrgeekman/Documents/MIPT/НИР/Papers/A Benchmark Corpus of English Misspellingsand a Minimally-supervised Model for Spelling Correction.pdf:pdf},
number = {Section 3},
pages = {76--86},
title = {{A Benchmark Corpus of English Misspellings and a Minimally-supervised Model for Spelling Correction}},
year = {2019}
}
@article{Brill2000,
abstract = {The noisy channel model has been applied to a wide range of problems, including spelling correction. These models consist of two components: a source model and a channel model. Very little research has gone into improving the channel model for spelling correction. This paper describes a new channel model for spelling correction, based on generic string to string edits. Using this model gives significant performance improvements compared to previously proposed models.},
author = {Brill, Eric and Moore, Robert C.},
doi = {10.3115/1075218.1075255},
file = {:home/mrgeekman/Documents/MIPT/НИР/Papers/An Improved Error Model for Noisy Channel Spelling Correction.pdf:pdf},
number = {Kukich 1992},
pages = {286--293},
title = {{An improved error model for noisy channel spelling correction}},
year = {2000}
}
@article{Unknown,
abstract = {Автоматические методы морфологического анализа и лемматизации, предназначенные для литературного русского языка, могут давать невысокие результаты, будучи применёнными к так называемым социальным медиа (микроблоги, социальные сети и т. д.). Одной из причин является орфографическая вариативность текстов в социальных медиа, зачастую вызванная опечатками. Мы предлагаем интегрировать модуль исправления опечаток в алгоритм морфологического анализа на примере Генерального интернет-корпуса русского языка (ГИКРЯ), что позволит осуществить расширенную лемматизацию. Также в работе предлагается новый алгоритм исправления опечаток, основанный на взвешенном расстоянии Левенштейна и проводится анализ типичных нарушений орфографической нормы в текстах социальных медиа.},
author = {Шаврина, Т О and Сорокин, А А and Ломоносова, М Г У М В and Shavrina, T O},
file = {:home/mrgeekman/Documents/MIPT/НИР/Papers/Русский язык/Modeling advanced lemmatization for Russian language using TnT-Russian morphological parser.pdf:pdf},
title = {{Моделирование расширенной лемматизации для русского языка на основе морфологического парсера TnT-Russian Modeling Advanced Lemmatization for Russian Language Using TnT ‑ Russian Morphological Parser}}
}
@article{Omelianchuk2020,
abstract = {In this paper, we present a simple and efficient GEC sequence tagger using a Transformer encoder. Our system is pre-trained on synthetic data and then fine-tuned in two stages: first on errorful corpora, and second on a combination of errorful and error-free parallel corpora. We design custom token-level transformations to map input tokens to target corrections. Our best single-model/ensemble GEC tagger achieves an {\$}F{\_}{\{}0.5{\}}{\$} of 65.3/66.5 on CoNLL-2014 (test) and {\$}F{\_}{\{}0.5{\}}{\$} of 72.4/73.6 on BEA-2019 (test). Its inference speed is up to 10 times as fast as a Transformer-based seq2seq GEC system. The code and trained models are publicly available.},
archivePrefix = {arXiv},
arxivId = {2005.12592},
author = {Omelianchuk, Kostiantyn and Atrasevych, Vitaliy and Chernodub, Artem and Skurzhanskyi, Oleksandr},
doi = {10.18653/v1/2020.bea-1.16},
eprint = {2005.12592},
file = {:home/mrgeekman/Documents/MIPT/НИР/Papers/GECToR – Grammatical Error Correction Tag, Not Rewrite.pdf:pdf},
number = {April},
pages = {163--170},
title = {{GECToR – Grammatical Error Correction: Tag, Not Rewrite}},
year = {2020}
}
@article{Sorokin2016a,
abstract = {This paper reports on the first competition on automatic spelling correction for Russian language - SpellRuEval - held within the framework of "Dialogue Evaluation". The competition aims to bring together groups of Russian academic researchers and IT-companies in order to gain and exchange the experience in automatic spelling correction, especially concentrating on social media texts. The data for the competition was taken from Russian segment of Live Journal. 7 teams took part in the competition, the best results were achieved by the model using edit distance and phonetic similarity for candidate search and n-gram language model for their reranking. We discuss in details the algorithms used by the teams, as well as the methodology of evaluation for automatic spelling correction.},
author = {Sorokin, A. A. and Baytin, A. V. and Galinskaya, I. E. and Rykunova, E. D. and Shavrina, T. O.},
file = {:home/mrgeekman/Documents/MIPT/НИР/Papers/Русский язык/SpellRueval the First Competition on automatic Spelling Correction for Russian.pdf:pdf},
issn = {20757182},
journal = {Komp'juternaja Lingvistika i Intellektual'nye Tehnologii},
keywords = {Automatic methods for processing Russian,Automatic spelling correction,Language of social media,Spelling correction},
pages = {660--673},
title = {{SPELLRUEVAL: The first competition on automatic spelling correction for Russian}},
year = {2016}
}
@article{Kiyono2020,
abstract = {The incorporation of pseudo data in the training of grammatical error correction models has been one of the main factors in improving the performance of such models. However, consensus is lacking on experimental configurations, namely, choosing how the pseudo data should be generated or used. In this study, these choices are investigated through extensive experiments, and state-of-the-art performance is achieved on the CoNLL-2014 test set (F0.5 = 65.0) and the official test set of the BEA-2019 shared task (F0.5 = 70.2) without making any modifications to the model architecture.},
archivePrefix = {arXiv},
arxivId = {1909.00502},
author = {Kiyono, Shun and Suzuki, Jun and Mita, Masato and Mizumoto, Tomoya and Inui, Kentaro},
doi = {10.18653/v1/d19-1119},
eprint = {1909.00502},
file = {:home/mrgeekman/Documents/MIPT/НИР/Papers/An Empirical Study of Incorporating Pseudo Data.pdf:pdf},
isbn = {9781950737901},
journal = {EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference},
pages = {1236--1242},
title = {{An empirical study of incorporating pseudo data into grammatical error correction}},
year = {2020}
}
@article{Kernighan1990,
abstract = {This paper describes a new program, correct, which takes words rejected by the Unix spell program, proposes a list of candidate corrections, and sorts them by probability. The probability scores are the novel contribution of this work. Probabilities are based on a noisy channel model. It is assumed that the typist knows what words he or she wants to type but some noise is added on the way to the keyboard (in the form of typos and spelling errors). Using a classic Bayesian argument of the kind that is popular in the speech recognition literature (Jelinek, 1985), one can often recover the intended correction, c, from a typo, t, by finding the correction c that maximizes Pr(c)Pr(tlc). The first factor, Pr(c), is a prior model of word probabilities; the second factor, Pr(tc), is a model of the noisy channel that accounts for spelling transformations on letter sequences (e.g., insertions, deletions, substitutions and reversals). Both sets of probabilities were trained on data collected from the Associated Press (AP) newswire. This text is ideally suited for this purpose since it contains a large number of typos (about two thousand per month).},
author = {Kernighan, Mark D. and Church, Kenneth W. and Gale, William A.},
doi = {10.3115/997939.997975},
file = {:home/mrgeekman/Documents/MIPT/НИР/Papers/A Spelling Correction Program Based on a Noisy Channel Model.pdf:pdf},
pages = {205--210},
title = {{A spelling correction program based on a noisy channel model}},
year = {1990}
}
@inproceedings{Ng2013,
abstract = {The CoNLL-2013 shared task was devoted to grammatical error correction. In this paper, we give the task definition, present the data sets, and describe the evaluation metric and scorer used in the shared task. We also give an overview of the various approaches adopted by the participating teams, and present the evaluation results.},
address = {Stroudsburg, PA, USA},
author = {Ng, Hwee Tou and Wu, Siew Mei and Briscoe, Ted and Hadiwinoto, Christian and Susanto, Raymond Hendy and Bryant, Christopher},
booktitle = {Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task},
doi = {10.3115/v1/W14-1701},
file = {:home/mrgeekman/Documents/MIPT/НИР/Papers/The CoNLL-2014 Shared Task on Grammatical Error Correction.pdf:pdf},
number = {July},
pages = {1--14},
publisher = {Association for Computational Linguistics},
title = {{The CoNLL-2014 Shared Task on Grammatical Error Correction}},
url = {http://aclweb.org/anthology/W14-1701},
year = {2014}
}
@article{Napoles2017,
abstract = {We present a new parallel corpus, JHU FLuency-Extended GUG corpus (JFLEG) for developing and evaluating grammatical error correction (GEC). Unlike other corpora, it represents a broad range of language proficiency levels and uses holistic fluency edits to not only correct grammatical errors but also make the original text more native sounding. We describe the types of corrections made and benchmark four leading GEC systems on this corpus, identifying specific areas in which they do well and how they can improve. JFLEG fulfills the need for a new gold standard to properly assess the current state of GEC.},
author = {Napoles, Courtney and Sakaguchi, Keisuke and Tetreault, Joel},
file = {:home/mrgeekman/Documents/MIPT/НИР/Papers/JFLEG A Fluency Corpus and Benchmark for Grammatical Error Correction.pdf:pdf},
journal = {arXiv},
pages = {229--234},
title = {{JFLEG: A fluency corpus and benchmark for grammatical error correction}},
volume = {2},
year = {2017}
}
@article{Devlin2019,
abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5{\%} (7.7{\%} point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
archivePrefix = {arXiv},
arxivId = {1810.04805},
author = {Devlin, Jacob and Chang, Ming Wei and Lee, Kenton and Toutanova, Kristina},
eprint = {1810.04805},
file = {:home/mrgeekman/Documents/MIPT/NLP/Lections/11/BERT.pdf:pdf},
isbn = {9781950737130},
journal = {NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference},
number = {Mlm},
pages = {4171--4186},
title = {{BERT: Pre-training of deep bidirectional transformers for language understanding}},
volume = {1},
year = {2019}
}
@article{Oflazer1996,
abstract = {This paper presents the notion of error-tolerant recognition with finite-state recognizers along with results from some applications. Error-tolerant recognition enables the recognition of strings that deviate mildly from any string in the regular set recognized by the underlying finite-state recognizer Such recognition has applications to error-tolerant morphological processing, spelling correction and approximate string matching in information retrieval. After a description of the concepts and algorithms involved, we give examples from two applications: in the context of morphological analysis, error-tolerant recognition allows misspelled input word forms to be corrected and morphologically analyzed concurrently. We present an application of this to error-tolerant analysis of the agglutinative morphology of Turkish words. The algorithm can be applied to morphological analysis of any language whose morphology has been fully captured by a single (and possibly very large) finite-state transducer, regardless of the word formation processes and morpholographemic phenomena involved. In the context of spelling correction, error-tolerant recognition can be used to enumerate candidate correct forms from a given misspelled string within a certain edit distance. Error-tolerant recognition can be applied to spelling correction for any language, if (a) it has a word list comprising all inflected forms, or (b) its morphology has been fully described by a finite-state transducer. We present experimental results for spelling correction for a number of languages. These results indicate that such recognition works very efficiently for candidate generation in spelling correction for many European languages (English, Dutch, French, German, and Italian, among others) with very large word lists of root and inflected forms (some containing well over 200,000 forms), generating all candidate solutions within 10 to 45 milliseconds (with an edit distance of 1) on a SPARCStation 10/41. For spelling correction in Turkish, error-tolerant recognition operating with a (circular) recognizer of Turkish words (with about 29,000 states and 119,000 transitions) can generate all candidate words in less than 20 milliseconds, with an edit distance of 1.},
archivePrefix = {arXiv},
arxivId = {cmp-lg/9504031},
author = {Oflazer, Kemal},
doi = {10.1184/r1/6287645.v1},
eprint = {9504031},
file = {:home/mrgeekman/Documents/MIPT/НИР/Papers/Error-tolerant finite-state recognition with applications.pdf:pdf},
issn = {08912017},
journal = {Computational Linguistics},
number = {1},
pages = {69--89},
primaryClass = {cmp-lg},
title = {{Error-tolerant Finite-state Recognition with Applications to Morphological Analysis and Spelling Correction}},
volume = {22},
year = {1996}
}
@inproceedings{Chen1996,
address = {Morristown, NJ, USA},
author = {Chen, Stanley F. and Goodman, Joshua},
booktitle = {Proceedings of the 34th annual meeting on Association for Computational Linguistics -},
doi = {10.3115/981863.981904},
file = {:home/mrgeekman/Documents/MIPT/НИР/Papers/An Empirical Study of Smoothing Techniques for Language Models.pdf:pdf},
isbn = {9781626239777},
pages = {310--318},
publisher = {Association for Computational Linguistics},
title = {{An empirical study of smoothing techniques for language modeling}},
url = {http://portal.acm.org/citation.cfm?doid=981863.981904},
volume = {213},
year = {1996}
}
@article{Devlin2019,
abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5{\%} (7.7{\%} point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
archivePrefix = {arXiv},
arxivId = {1810.04805},
author = {Devlin, Jacob and Chang, Ming Wei and Lee, Kenton and Toutanova, Kristina},
eprint = {1810.04805},
file = {:home/mrgeekman/Documents/MIPT/NLP/Lections/11/BERT.pdf:pdf},
isbn = {9781950737130},
journal = {NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference},
mendeley-groups = {ML/NLP},
number = {Mlm},
pages = {4171--4186},
title = {{BERT: Pre-training of deep bidirectional transformers for language understanding}},
volume = {1},
year = {2019}
}

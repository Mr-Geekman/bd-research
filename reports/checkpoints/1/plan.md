# Примерный план для контроля

## Название

Применение BERT для исправления опечаток в русскоязычных текстах.

## Актуальность работы/Анализ предметной области

### Виды ошибок, которые можно рассматривать

* grammatical -- грамматические

Грамматические ошибки, как правило, заключаются в неправильном употреблении слов. Например, используется форма единственного числа, когда нужна форма множественного числа.

* spelling -- орфографические, касающие написания слов без учета правил переноса, заглавных букв. 

Орфографические ошибки. Неправильное написание услышанного слова. По сути это неправильный выбор букв для записи чего-либо.

* typo -- опечатки

Ошибки, возникающие при наборе текста на клавиатуре.

### Задачи

1. GEC -- grammatical error correction
2. spelling correction

### Датасеты и метрики

### Метрики

Текст разбивается на предложения. В каждом предложении $i$ есть предложенные изменения $g_i$ и истинные $e_i$. Тогда получим:

$$
R = \frac{\sum_{i=1}^n |g_i \cap e_i|}{\sum_{i=1}^n |g_i|}
\\
P = \frac{\sum_{i=1}^n |g_i \cap e_i|}{\sum_{i=1}^n |e_i|}
$$

Мы оцениваем именно $F_{0.5}$.

Реализуется скорерами:
   * MaxMatch (M2) (CoNLL-2014)
   * ERRANT (BEA-2019) -- по сути усовершенствованная версия предыдущего, но дает несколько иные скоры

Есть еще GLEU метрика, используемая в JFLEG датасете. Это аналог BLEU для MT, т.е смотрится пересечение n-грамм.

Для русского языка была использована похожая метрика, только $F_1$, но вот скоринг был устроен иначе. Там выравнивались исходное и исправленное предложения и так уже находились исправления. Код самого скорера я пока не нашел, возможно, можно использовать ERRANT/MaxMatch скореры, так как они открыты.

### Датасеты

#### Английский язык
* [CLC FCE Dataset](https://ilexir.co.uk/datasets/index.html)
  * GEC
  * 2500 эссе, написанных в качестве экзаменационного задания
  * 500k слов
  * 80 типов ошибок, в т.ч. опечатки
  * При при более тщательном анализе можно обнаружить, что многие орфографические ошибки помечены другими категориями ошибок.
* [CoNLL-2014](https://www.comp.nus.edu.sg/~nlp/conll14st.html)
  * GEC
  * Дается эссе на английском языке, написанное, изучающим английский, как второй язык. Целью является детекция и исправление всех грамматических ошибок и возвращение исправленного эссе
  * 28 типов ошибок
  * train: 1M токенов
  * test: 30k токенов -- мало  
  * [Рейтинг](https://paperswithcode.com/sota/grammatical-error-correction-on-conll-2014)
* [The TOEFL-Spell Corpus](https://github.com/EducationalTestingService/toefl-spell)
  * spelling correction
  * 883 эссе
  * all: 296k токенов
  * 6 121 ошибка
* [JFLEG](https://github.com/keisks/jfleg)
  * GEC
  * all: 1.5k предложений
* [Lang-8](https://sites.google.com/site/naistlang8corpora/home/readme-en)
  * GEC
  * all: 100k предложений
* [NUCLE](https://www.comp.nus.edu.sg/~nlp/corpora.html)
  * GEC
  * all: 57k предложений
* [BEA-2019](https://www.cl.cam.ac.uk/research/nl/bea2019st/)
  * GEC
  * train: 628k токенов
  * valid: 87k токенов
  * test: 86k токенов
  * Разные уровни сложности текстов от beginner до native
  * [Рейтинг](https://www.paperswithcode.com/sota/grammatical-error-correction-on-bea-2019-test)


#### Русский язык: 
* [SpellRuEval competition](http://www.dialog-21.ru/en/evaluation/2016/spelling_correction/)
  * Можно найти на странице соревнования
  * GEC. Кажется сначала, что тут spelling correction, но на самом деле требуется исправлять и грамматические ошибки, что описано в статье про соревнование.
  * train: нет
  * valid: 2k предложений
  * test: 2k предложений (участника дали больше, но тестировали только на 2k)

### Существующие решения

#### Noisy channel

Статьи: 
* A mathematical theory of communications
* A Spelling Correction Program Based on a Noisy Channel Model

Классический подход, требующий достаточно много данных для обучения.

#### Обнаружение, поиск кандидатов, отбор

Статья: On using context for automatic correction of non-word misspellings in student essays

Модель для spelling correction. 

Состоит из решения трех подзадач:
1. Обнаружение ошибок.
2. Генерация кандидатов
3. Ранжирование кандидатов

Этот подход широко используется во многих моделях. 

Посмотрим на каждый этап в отдельности:
1. Можем просто искать слова не из словаря. Подход простой, но его можно использовать.
2. Для генерации ищутся все словарные слова на каком-то алгоритмически заданном расстоянии редактирования от рассматриваемого слова.
3. Берется множество признаков и ранжируется при помощи, например, модели логистической регрессии:
    * Расстояние Левенштейна
    * Языковая модель
    * Фонетическое расстояние Левештейна
    * Частоты слов
    * PMI
    * Эмбеддинги
    * и др.

#### Стандартные решения

* GNU Aspell.
* Hunspell -- задумывался как лучше работающий с языками с богатой морфологией.

#### xfspell

[Статья на веб-сайте](http://www.realworldnlpbook.com/blog/unreasonable-effectiveness-of-transformer-spell-checker.html)

Основан на архитектуре трансформера. По сути решает задачу MT. Использует также backtranslation для генерации дополнительных обучающих данных.

#### Добавление копирования

Статья: Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data

Перевод -- не самая подходящая задача для GEC, поскольку до 80% слов остаются неизменными. Авторы статьи внедрили механизм копирования слов из исходной последовательности, который хорошо показал себя в задаче суммаризаци.

Авторы также предобучили denoising auto-encoder. По сути они взяли большой корпус. Испортили его и натренировали энкодер трансформера на предсказание исправлений (чем-то похоже на MLM).

Отдельно был обучен и декодер.

Были предложены unsupervised задачи для GEC: разметка правильных токенов (надо отметить токен корректный или нет), копирование предложений (если предложение выглядит правильным, то надо стимулировать модель сразу его копировать).

Написано также, что в работе перед обучением над обучающими данными был проведен spell-checking при помощи статистической модели.

#### PIE

Статья: Parallel Iterative Edit Models for Local Sequence Transduction

Авторы привели задачу к sequence labeling и предсказывают операции, которые надо произвести над токенами. Модели требуется несколько итераций, чтобы получить ответ. Внутри итерации можно работать параллельно. Не требуется ждать, пока сгенерируется новый токен, как в задачах MT, что сильно ускоряет это решение.

Предсказывающая модель -- предобученный модифицированный BERT.

Предварительно также был проведен spellchecking.

#### Генерация дополнительных данных

Статья: An Empirical Study of Incorporating Pseudo Data into Grammatical Error Correction

Статья изучает различные способы генерации дополнительных данных для обучения. Они использовали трансформер в качестве модели.

Способы:
* DirectNoise -- добавление шума непосредственно в данные (замена символов, перестановки, удаления)
* Backtranslation (noisy) -- перевод с языка "без ошибок" на язык "с ошибками" с добавлением шума в вероятноти при генерации
* Backtranslation (sample) -- перевод с языка "без ошибок" на язык "с ошибками" простым сэмплированием без использования beam-search

#### GECToR (SOTA)

Статья: GECToR – Grammatical Error Correction: Tag, Not Rewrite

Создан командой из Grammarly.

Похожим образом на PIE решается задача sequence tagging. Для этого используется энкодер трансформера (BERT, RoBERTa, XLNet), два линейных слоя, softmax. Для полного завершения преобразования требуется выполнить несколько итераций алгоритма.

Помимо этого используются приемы с генерацией дополнительных данных из вышеуказанной статьи.

## Анализ аналогов

### Английский язык

| GEC system                      | CoNLL-2014 (M2) | BEA-2019 (ERRANT) |
| ------------------------------- | --------------- | ----------------- |
| Copy Transformer (Ensemble)     | 61.2            | -                 |
| PIE (Ensemble)                  | 61.2            | -                 |
| Transformer (Ensemble)          | 65.0            | 70.2              |
| GECToR (XLNet)                  | 65.3            | 72.4              |
| GECToR (BERT + RoBERTa + XLNet) | 66.5            | 73.6              |

1. Copy Transformer -- "Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data"
2. Transformer -- "An Empirical Study of Incorporating Pseudo Data into Grammatical Error Correction"

### Русский язык

Можно заметить про сложность русского языка по сравнению с английским в этой задаче -- см. [отчет к соревнованию SpellRuEval](http://www.dialog-21.ru/media/3427/sorokinaaetal.pdf).

| GEC system           | Precision | Recall | F-measure |
| -------------------- | --------- | ------ | --------- |
| Yandex.Speller       | 83.09     | 59.86  | 69.59     |
| SpellRuEval Baseline | 55.91     | 46.41  | 50.72     |
| SpellRuEval Winner   | 81.98     | 69.25  | 75.07     |

[Дополнительное сравнение](http://docs.deeppavlov.ai/en/master/features/models/spelling_correction.html)

## Цель работы

Изучение применимости модели BERT для исправления ошибок в русскоязычных текстах.

## Используемые технологии/библиотеки

* transformers
* ruBERT
* DeepPavlov: код для поиска кадидатов

## Архитектура решения

## План работы

1) Сделать модель, которая ранжирует отобранных кандидатов при помощи BERT. Протестировать ее на англоязычном датасете, затем на русскоязычном.
2) Ввести ранжирующую модель со множеством признаков, как в вашей статье, только заменить lm на BERT. Протестировать ее.
3) Попробовать дообучить BERT на MLM для датасета и посмотреть, что выйдет из этого. Возможно, имеет смысл делать MLM на близких по описанию словам. В качестве положительных примеров брать правильное слово, а в качестве отрицательных похожее, но неправильное.
4) Возможно, попробовать другие модели (GPT)
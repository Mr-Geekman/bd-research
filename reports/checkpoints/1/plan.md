# Примерный план для контроля

## Название

Исправление опечаток и грамматических ошибок для русскоязычных текстов при помощи BERT.

## Актуальность работы/Анализ предметной области

### Виды ошибок, которые можно рассматривать

* grammatical -- грамматические

Грамматические ошибки, как правило, заключаются в неправильном употреблении слов. Например, используется форма единственного числа, когда нужна форма множественного числа.

* spelling -- орфографические, касающие написания слов без учета правил переноса, заглавных букв. 

Орфографические ошибки. Неправильное написание услышанного слова. По сути это неправильный выбор букв для записи чего-либо.

* typo -- опечатки

Ошибки, возникающие при наборе текста на клавиатуре.

### Задачи

1. GEC -- grammatical error correction
2. spelling correction

### Датасеты и метрики

### Метрики

Текст разбивается на предложения. В каждом предложении $i$ есть предложенные изменения $g_i$ и истинные $e_i$. По их соответствиям считается Precision, Recall. Мы оцениваем именно F-1/2.

Реализуется скорерами:
   * MaxMatch (M2) (CoNLL-2014)
   * ERRANT (BEA-2019) -- по сути усовершенствованная версия предыдущего, но дает несколько иные скоры

Есть еще GLEU метрика, используемая в JFLEG датасете. Это аналог BLEU для MT, т.е смотрится пересечение n-грамм.

Для русского языка была использована похожая метрика, только F1, но вот скоринг был устроен иначе -- его код я пока не видел.

### Датасеты

#### Английский язык
* [CLC FCE Dataset](https://ilexir.co.uk/datasets/index.html)
  * GEC
  * 2500 эссе, написанных в качестве экзаменационного задания
  * 500k слов
  * 80 типов ошибок, в т.ч. опечатки
  * При при более тщательном анализе можно обнаружить, что многие орфографические ошибки помечены другими категориями ошибок.
* [CoNLL-2014](https://www.comp.nus.edu.sg/~nlp/conll14st.html)
  * GEC
  * Дается эссе на английском языке, написанное, изучающим английский, как второй язык. Целью является детекция и исправление всех грамматических ошибок и возвращение исправленного эссе
  * 28 типов ошибок
  * train: 1M токенов
  * test: 30k токенов -- мало  
  * [Рейтинг-1](https://paperswithcode.com/sota/grammatical-error-correction-on-conll-2014)
  * [Рейтинг-2](http://nlpprogress.com/english/grammatical_error_correction.html)
* [The TOEFL-Spell Corpus](https://github.com/EducationalTestingService/toefl-spell)
  * spelling correction
  * 883 эссе
  * all: 296k токенов
  * 6 121 ошибка
* [JFLEG](https://github.com/keisks/jfleg)
  * GEC
  * all: 1.5k предложений
* [Lang-8](https://sites.google.com/site/naistlang8corpora/home/readme-en)
  * GEC
  * all: 100k предложений
* [NUCLE](https://www.comp.nus.edu.sg/~nlp/corpora.html)
  * GEC
  * all: 57k предложений
* [BEA-2019](https://www.cl.cam.ac.uk/research/nl/bea2019st/)
  * GEC
  * train: 628k токенов
  * valid: 87k токенов
  * test: 86k токенов
  * Разные уровни сложности текстов от beginner до native
  * [Рейтинг-1](https://www.paperswithcode.com/sota/grammatical-error-correction-on-bea-2019-test)
  * [Рейтинг-2](http://nlpprogress.com/english/grammatical_error_correction.html)


#### Русский язык: 
* [SpellRuEval competition](http://www.dialog-21.ru/en/evaluation/2016/spelling_correction/)
  * Можно найти на странице соревнования
  * GEC. Кажется сначала, что тут spelling correction, но на самом деле требуется исправлять и грамматические ошибки, что описано в статье про соревнование.
  * train: нет
  * valid: 2k предложений
  * test: 2k предложений (участникам дали больше, но тестировали только на 2k)

### Существующие решения

#### Стандартные решения

* GNU Aspell.
* Hunspell -- задумывался как лучше работающий с языками с богатой морфологией.
* JamSpell
* Яндекс.Спеллер

#### Noisy channel, Weighted Damerau–Levenshtein distance, EM

Статьи: 
* A mathematical theory of communications
* A Spelling Correction Program Based on a Noisy Channel Model
* An Improved Error Model for Noisy Channel Spelling Correction

Классический подход

#### Поиск кандидатов, ранжирование

Статья: On using context for automatic correction of non-word misspellings in student essays

Модель для spelling correction. 

Состоит из решения двух подзадач:
1. Поиск кандидатов
2. Ранжирование кандидатов

Этот подход широко используется во многих моделях. 

Посмотрим на каждый этап в отдельности:
1. Для генерации ищутся все словарные слова на каком-то алгоритмически заданном расстоянии редактирования от рассматриваемого слова.
2. Берется множество признаков и ранжируется при помощи, например, модели логистической регрессии:
    * Расстояние Дамерау - Левенштейна
    * Языковая модель
    * Фонетическое расстояние Левештейна
    * Частоты слов
    * PMI
    * Эмбеддинги
    * и др.

#### xfspell

[Статья на веб-сайте](http://www.realworldnlpbook.com/blog/unreasonable-effectiveness-of-transformer-spell-checker.html)

Основан на архитектуре трансформера. По сути решает задачу MT. Использует также backtranslation для генерации дополнительных обучающих данных.

#### Добавление копирования

Статья: Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data

Перевод -- не самая подходящая задача для GEC, поскольку до 80% слов остаются неизменными. Авторы статьи внедрили механизм копирования слов из исходной последовательности, который хорошо показал себя в задаче суммаризаци.

Авторы также предобучили denoising auto-encoder. По сути они взяли большой корпус. Испортили его и натренировали энкодер трансформера на предсказание исправлений (чем-то похоже на MLM).

Отдельно был обучен и декодер.

Были предложены unsupervised задачи для GEC: разметка правильных токенов (надо отметить токен корректный или нет), копирование предложений (если предложение выглядит правильным, то надо стимулировать модель сразу его копировать).

Написано также, что в работе перед обучением над обучающими данными был проведен spell-checking при помощи статистической модели.

#### PIE

Статья: Parallel Iterative Edit Models for Local Sequence Transduction

Авторы привели задачу к sequence labeling и предсказывают операции, которые надо произвести над токенами. Модели требуется несколько итераций, чтобы получить ответ. Внутри итерации можно работать параллельно. Не требуется ждать, пока сгенерируется новый токен, как в задачах MT, что сильно ускоряет это решение.

Предсказывающая модель -- предобученный модифицированный BERT.

Предварительно также был проведен spellchecking.

#### Генерация дополнительных данных

Статья: An Empirical Study of Incorporating Pseudo Data into Grammatical Error Correction

Статья изучает различные способы генерации дополнительных данных для обучения. Они использовали трансформер в качестве модели.

Способы:
* DirectNoise -- добавление шума непосредственно в данные (замена символов, перестановки, удаления)
* Backtranslation (noisy) -- перевод с языка "без ошибок" на язык "с ошибками" с добавлением шума в вероятноти при генерации
* Backtranslation (sample) -- перевод с языка "без ошибок" на язык "с ошибками" простым сэмплированием без использования beam-search

Статья: Neural Grammatical Error Correction Systems with Unsupervised Pre-training on Synthetic Data

Эта статья изучает генерацию синтетических данных unsupervised. Они делали ошибки в словах исходя из предложений Aspell и портили сами слова.

#### GECToR (SOTA)

Статья: GECToR – Grammatical Error Correction: Tag, Not Rewrite

Создан командой из Grammarly.

Похожим образом на PIE решается задача sequence tagging. Для этого используется энкодер трансформера (BERT, RoBERTa, XLNet), два линейных слоя, softmax. Для полного завершения преобразования требуется выполнить несколько итераций алгоритма.

Помимо этого используются приемы с генерацией дополнительных данных из вышеуказанной статьи.

## Анализ аналогов

### Английский язык

| GEC system                      | CoNLL-2014 (M2) | BEA-2019 (ERRANT) |
| ------------------------------- | --------------- | ----------------- |
| Copy Aug. Transformer (Ensemble)     | 61.2            | -                 |
| PIE (Ensemble)                  | 61.2            | -                 |
| Transformer (Ensemble)          | 65.0            | 70.2              |
| GECToR (XLNet)                  | 65.3            | 72.4              |
| GECToR (BERT + RoBERTa + XLNet) | **66.5**        | **73.6**          |

1. Copy Transformer -- "Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data"
2. Transformer -- "An Empirical Study of Incorporating Pseudo Data into Grammatical Error Correction"

### Русский язык

Можно заметить про сложность русского языка по сравнению с английским в этой задаче -- см. [отчет к соревнованию SpellRuEval](http://www.dialog-21.ru/media/3427/sorokinaaetal.pdf).

| GEC system           | Precision   | Recall    | F-measure  |
| -------------------- | ----------- | --------- | ---------- |
| Yandex.Speller       | **83.09**   | 59.86     | 69.59      |
| JamSpell             | 44.57       | 35.69     | 39.64      |
| SpellRuEval Baseline | 55.91       | 46.41     | 50.72      |
| SpellRuEval Winner   | 81.98       | **69.25** | **75.07**  |

[Дополнительное сравнение](http://docs.deeppavlov.ai/en/master/features/models/spelling_correction.html)

## Цель работы

Исследование применимости модели BERT к задаче исправления опечаток и грамматических ошибок в русскоязычных текстах.

## Используемые технологии/библиотеки

* transformers
* ruBERT
* DeepPavlov: код для поиска кадидатов, код для поиска весов взвешенного расстояния Левенштейна.

## Архитектура решения

Было решено начать с модели, основанной на ранжировании в связи с небольшим количеством данных и хорошими показателями согласно SpellRuEval.

Поиск кандидатов будет осуществляться на основании расстояния Дамерау -- Левенштейна при помощи префиксного бора. За основу будет взят [spelling-correction модуль](https://github.com/deepmipt/DeepPavlov/tree/0.12.1/deeppavlov/models/spelling_correction)} из библиотеки DeepPavlov.

Полученные кандидаты будут отранжированны на основе признаков:
* Взвешенное расстояние Дамерау -- Левенштейна.
* Вероятность BERT MLM.

Веса для BERT будут взяты из RuBERT.

## Планы работы

1) Создание модели, ранжирующей на основе BERT MLM и ее тестирование на русскоязычных и англоязычных датасетах.
2) Введение дополнительных признаков, как в решении-победителе SpellRuEval.
3) Дообучение BERT на MLM для датасета. Возможно, имеет смысл делать MLM на близких по описанию словам. В качестве положительных примеров брать правильное слово, а в качестве отрицательных похожее, но неправильное.
4) Возможно, испытание других моделей для предсказания вероятностей слов (например, GPT).